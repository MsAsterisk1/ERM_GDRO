{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e227b8",
   "metadata": {
    "id": "f3e227b8"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3261d496",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3261d496",
    "outputId": "9206134a-1091-4601-e9cb-c2253cfeb2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efurst1\\PycharmProjects\\ERM_GDRO\n"
     ]
    }
   ],
   "source": [
    "# For use on local machine\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6d8e1",
   "metadata": {
    "id": "92f6d8e1"
   },
   "source": [
    "# Results Visualization\n",
    "\n",
    "Data loading and plotting functions to visualize the results given by run.py  \n",
    "Put the path of the folder containing the results in load_dir and run the cells to see results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fed7c",
   "metadata": {},
   "source": [
    "## Defining functions & parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1550ad5",
   "metadata": {
    "id": "c1550ad5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# .csv to load results from\n",
    "load_path = 'test_results/mnist/accuracies.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ace5d7",
   "metadata": {
    "id": "b3ace5d7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_acc(drop_epochs=[], err_margin=0):\n",
    "    loaded_accuracies = pd.read_csv(load_path)\n",
    "    N = max(loaded_accuracies[\"trial\"]) + 1\n",
    "    epochs = max(loaded_accuracies[\"epoch\"]) + 1\n",
    "    subtypes = list(loaded_accuracies[\"subtype\"].unique())\n",
    "    algorithms = loaded_accuracies.columns\n",
    "\n",
    "    results = loaded_accuracies.drop(columns=[\"trial\", \"epoch\", \"subtype\"]).to_dict('list')\n",
    "    results_df = pd.DataFrame(results, index=pd.MultiIndex.from_product([range(N), range(epochs), subtypes], names=[\"trial\", \"epoch\", \"subtype\"]))\n",
    "    \n",
    "    trial_means = results_df.stack().unstack(level=0).mean(axis=1).unstack(level=2)\n",
    "    trial_errs = results_df.stack().unstack(level=0).std(axis=1).unstack(level=2) / (N ** 0.5)\n",
    "\n",
    "    trial_means.drop(drop_epochs, level=0, axis=0, inplace=True)\n",
    "    hide = []\n",
    "    \n",
    "    subtypes = [\"Overall\", \"8\"]\n",
    "\n",
    "    f, a = plt.subplots(len(subtypes), 1)\n",
    "\n",
    "    # plot subtypes sensitivity\n",
    "\n",
    "    for i in range(len(subtypes)):\n",
    "        plot_data = trial_means.drop(columns=hide).xs(subtypes[i], level=1)\n",
    "        plot_data.plot(ylim=[0.6,1],xlabel=\"Epoch\",ylabel=\"Accuracy\",kind='line',title=subtypes[i],ax=a[i],figsize=(24, 6 * len(subtypes)),grid=True)\n",
    "        plot_errs = trial_errs.drop(columns=hide).xs(key=subtypes[i], level=1)\n",
    "        for col in plot_data.columns:\n",
    "            a[i].fill_between(list(plot_data.index), plot_data[col] + err_margin * plot_errs[col], plot_data[col] - err_margin * plot_errs[col], alpha=0.25)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E4X11ykAAunM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "E4X11ykAAunM",
    "outputId": "59725333-309d-4151-c19b-74974e9b66e1"
   },
   "outputs": [],
   "source": [
    "# statisitical tests comparing to ERM\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def ttest(p_threshold=0.05):\n",
    "    print(f't-tests with significance threshold p<{p_threshold}\\n')\n",
    "    ttest_dataframes = {}\n",
    "\n",
    "    loaded_accuracies = pd.read_csv(load_path)\n",
    "    N = max(loaded_accuracies[\"trial\"]) + 1\n",
    "    epochs = max(loaded_accuracies[\"epoch\"]) + 1\n",
    "    subtypes = list(loaded_accuracies[\"subtype\"].unique())\n",
    "    algorithms = loaded_accuracies.columns\n",
    "\n",
    "    results = loaded_accuracies.drop(columns=[\"subtype\", \"epoch\", \"trial\"]).to_dict('list')\n",
    "    results_df = pd.DataFrame(results, index=pd.MultiIndex.from_product([range(N), range(epochs), subtypes], names=[\"trial\", \"epoch\", \"subtype\"]))\n",
    "\n",
    "    for s in range(len(subtypes)):\n",
    "        epoch = epochs - 1\n",
    "\n",
    "        subtype_data = results_df.xs(subtypes[s], level=2).xs(epoch, level=1)\n",
    "        erm_data = subtype_data[\"ERMLoss\"].values\n",
    "\n",
    "        print(subtypes[s])\n",
    "        for algorithm in results_df.columns:\n",
    "            if algorithm != \"ERMLoss\":\n",
    "                algorithm_data = subtype_data[algorithm].values\n",
    "                stat, p = ttest_ind(algorithm_data, erm_data)\n",
    "\n",
    "                print(f'ERMLoss: {erm_data.mean():.3f}, 1.96*stdErr: {(1.96 * erm_data.std(ddof=1) / (len(erm_data) ** 0.5)):.2e}')\n",
    "                print(f'{algorithm}: {algorithm_data.mean():.3f}, 1.96*stdErr: {(1.96 * algorithm_data.std(ddof=1) / (len(algorithm_data) ** 0.5)):.2e}')\n",
    "                if p < p_threshold:\n",
    "                    print(f'{algorithm if stat > 0 else \"ERMLoss\"} greater with p = {p:.2e}')\n",
    "                else:\n",
    "                    print(f'No significant difference with p = {p:.2e}')\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a465c5",
   "metadata": {},
   "source": [
    "## Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b8ce6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6e1b8ce6",
    "outputId": "b1538dcf-ce63-45fc-e591-4b2cbc3c4f58",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_acc(err_margin=1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest(p_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71853da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a00a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(\"waterbirds\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a6323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds._metadata_array = 2 * ds._metadata_array[:, 1] + ds._metadata_array[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "dstrain = ds.get_subset(\n",
    "    \"train\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((448, 448)), transforms.ToTensor(), transforms.Lambda(lambda x: x.to('cuda'))]\n",
    "    ),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68abc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import InfiniteDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(InfiniteDataLoader(dstrain, batch_size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain[0][0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28093fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process_data_utils import get_waterbirds_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(get_waterbirds_dataloaders(128, device='cuda')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa15084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\efurst1\\PycharmProjects\\ERM_GDRO\\run.py\", line 1, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n"
     ]
    }
   ],
   "source": [
    "!python run.py waterbirds --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476ee24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "run_test.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "REU",
   "language": "python",
   "name": "reu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
