{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ca7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits nodules between training and testing sets, using subtype data to stratify the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b3a17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb5f66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data folder\n",
    "data_folder = \"../data/\"\n",
    "\n",
    "# Paths to data csv files\n",
    "subtypes_path = data_folder + \"lidc_spic_subgrouped.csv\"\n",
    "max_slice_path = data_folder + \"LIDC_20130817_AllFeatures2D_MaxSlicePerNodule_inLineRatings.csv\"\n",
    "\n",
    "# Filepath to store the training & testing flags for each nodule\n",
    "split_path = data_folder + \"lidc_train_test_split_stratified.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f59bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort each nodule by subgroups\n",
    "\n",
    "subtype_df = pd.read_csv(subtypes_path)\n",
    "subtype_col = \"subgroup\"\n",
    "nodule_col = \"noduleID\"\n",
    "\n",
    "nodules = {}\n",
    "\n",
    "for subtype in subtype_df[subtype_col].unique():\n",
    "    nodules[subtype] = subtype_df[subtype_df[subtype_col] == subtype][nodule_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db9c32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample a portion of each subtype into training and test sets\n",
    "\n",
    "train_frac = 0.8\n",
    "\n",
    "train_set, test_set = [], []\n",
    "\n",
    "for subtype in nodules:\n",
    "    threshold = int(train_frac * len(nodules[subtype]))\n",
    "    \n",
    "    # shuffle nodules to ensure random sampling\n",
    "    nodule_list = nodules[subtype].values\n",
    "    random.shuffle(nodule_list)\n",
    "    \n",
    "    train_set.extend(nodule_list[:threshold])\n",
    "    test_set.extend(nodule_list[threshold:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "273a632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format into dataframe\n",
    "\n",
    "train_test_df = pd.DataFrame({nodule_col: subtype_df[nodule_col], \"dataset\": np.empty(len(subtype_df[nodule_col]))})\n",
    "\n",
    "for i in subtype_df.index:\n",
    "    nodule_id = subtype_df.at[i, nodule_col]\n",
    "    train_test_df.at[i, \"dataset\"] = \"train\" if nodule_id in train_set else \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "659c5707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "\n",
    "train_test_df.to_csv(split_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cb944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU",
   "language": "python",
   "name": "reu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
