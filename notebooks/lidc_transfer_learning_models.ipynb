{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtzig/LIDC_GDRO/blob/main/notebooks/lidc_transfer_learning_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXP5BUZY7SbH"
      },
      "source": [
        "#ERM CNN Model for Malignancy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First We setup the repo"
      ],
      "metadata": {
        "id": "3mlU0-uy8Ez3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMqJTbcB7SbG",
        "outputId": "a1777d85-5d63-4a2c-dac0-533706c31a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LIDC_GDRO'...\n",
            "remote: Enumerating objects: 3329, done.\u001b[K\n",
            "remote: Counting objects: 100% (404/404), done.\u001b[K\n",
            "remote: Compressing objects: 100% (199/199), done.\u001b[K\n",
            "remote: Total 3329 (delta 248), reused 350 (delta 205), pack-reused 2925\u001b[K\n",
            "Receiving objects: 100% (3329/3329), 56.11 MiB | 13.29 MiB/s, done.\n",
            "Resolving deltas: 100% (3060/3060), done.\n",
            "Checking out files: 100% (5393/5393), done.\n",
            "/content/LIDC_GDRO\n"
          ]
        }
      ],
      "source": [
        "# Only run if on Colab\n",
        "#%cd .. #run this on local machine\n",
        "!git clone https://github.com/mtzig/LIDC_GDRO.git\n",
        "%cd /content/LIDC_GDRO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FfxoU2RZ7SbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeca322e-b543-49c7-8d98-27c5267d234e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/mtzig/LIDC_GDRO\n",
            "   3c921ee..758af5a  main       -> origin/main\n",
            "Updating 3c921ee..758af5a\n",
            "Fast-forward\n",
            " image_data_utils.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ],
      "source": [
        "# !git pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "BoTdOzRN7hbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c198d11-6680-428b-a256-3e1af919b7f5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dataloaders import InfiniteDataLoader\n",
        "from datasets import NoduleDataset, SubclassedNoduleDataset\n",
        "from models import VGGNet, ResNet18\n",
        "from loss import ERMLoss, GDROLossAlt, GDROLoss\n",
        "from train import train, test\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "Gor5x5428B0V"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Good to go!\")\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"Using cpu\")\n",
        "    DEVICE = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6Vy4YCE8UHA",
        "outputId": "31fc09a4-95ea-4347-9f0d-25440bb25f9b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good to go!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Models"
      ],
      "metadata": {
        "id": "SFdoHrHh6aNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class testModel(nn.Module):\n",
        "\n",
        "    def __init__(self, device='cpu', pretrained=True, freeze=True):\n",
        "        super(testModel, self).__init__()\n",
        "\n",
        "        self.model = torchvision.models.resnet18(pretrained=pretrained).to(device) #torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True).to(device)\n",
        "        \n",
        "        if freeze:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "\n",
        "            # for param in self.model.layer4.parameters():\n",
        "            #     param.requires_grad = True\n",
        "\n",
        "        self.model.fc = nn.Sequential(\n",
        "          nn.Linear(in_features=512, out_features=36, bias=True, device=device),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Dropout(p=0.5, inplace=False),\n",
        "          nn.Linear(in_features=36, out_features=2, bias=True, device=device)\n",
        "          # nn.Linear(in_features=36, out_features=1, bias=True, device=device)\n",
        "        )\n",
        "\n",
        "        for layer in self.model.fc:\n",
        "            if hasattr(layer, 'weight'):\n",
        "                nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze()\n"
      ],
      "metadata": {
        "id": "vw7pTVUU6dK1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Next We get our data"
      ],
      "metadata": {
        "id": "XHCAFpSD8WpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we get the data"
      ],
      "metadata": {
        "id": "znDlzTCe-1AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from image_data_utils import getImages, getTrainValSplit, getSubtypedDataLoader"
      ],
      "metadata": {
        "id": "ri-LhZtGkbyI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = getImages(device=DEVICE)\n",
        "\n",
        "train_split = SubclassedNoduleDataset(*train_data)\n",
        "\n",
        "test_set = SubclassedNoduleDataset(*test_data)\n",
        "train_set, val_set = getTrainValSplit(train_set, split_percent = 0.95)"
      ],
      "metadata": {
        "id": "XNgJ_iLjk44R"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader = getSubtypedDataLoader(train_set,5)"
      ],
      "metadata": {
        "id": "uZ-z-g8OlFKd"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = InfiniteDataLoader(val_set, len(val_set))\n",
        "test_loader = InfiniteDataLoader(test_set, len(test_set))"
      ],
      "metadata": {
        "id": "0vYvA0fjmhFi"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = InfiniteDataLoader(train_set, 128)"
      ],
      "metadata": {
        "id": "hamaequxqjvF"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now we create the model and setup training"
      ],
      "metadata": {
        "id": "zxegLjbZ5Dex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we make our model"
      ],
      "metadata": {
        "id": "bScAw_b25T1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = testModel(device=DEVICE, pretrained=True, freeze=False)"
      ],
      "metadata": {
        "id": "iAG-NHBe5KE6"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn = ERMLoss(model,torch.nn.CrossEntropyLoss(),{}, subclassed=True)\n",
        "# loss_fn = GDROLoss(model,torch.nn.CrossEntropyLoss(),{'groupdro_eta':0.01}, )\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.005)#lr=0.001, weight_decay=0.005)\n",
        "\n",
        "loss_fn = GDROLossAlt(model,torch.nn.CrossEntropyLoss(),0.1, 4) \n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.005)#lr=0.001, weight_decay=0.005)\n",
        "\n",
        "# loss_fn = ERMLoss(model,torch.nn.functional.binary_cross_entropy_with_logits,{})\n"
      ],
      "metadata": {
        "id": "RmxOUGwp5WDm"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also make learning rate scheduler"
      ],
      "metadata": {
        "id": "5Q6lWeSjMwVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=2, verbose=True)"
      ],
      "metadata": {
        "id": "DAR_w5zNMy9w"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Now we train the model"
      ],
      "metadata": {
        "id": "jHLB-GyZ7M2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15#40\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    train(train_loader, model, loss_fn, optimizer, verbose=True)\n",
        "    accuracies = test(val_loader, model, verbose=True)\n",
        "    scheduler.step(min(accuracies[1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sTWriyTrL-s",
        "outputId": "9bd37aa1-72c5-4823-e162-881af4a64684"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "Average training loss: 0.8673823841593482\n",
            "Accuracy: 0.7491749174917491 \n",
            "Accuracy over subgroups: [0.33333333 0.60135135 0.97826087 0.8627451 ] \n",
            "Worst Group Accuracy: 0.3333333333333333\n",
            "Epoch 2/15\n",
            "Average training loss: 0.483043645593253\n",
            "Accuracy: 0.7722772277227723 \n",
            "Accuracy over subgroups: [0.3        0.71875    0.91358025 0.80769231] \n",
            "Worst Group Accuracy: 0.3\n",
            "Epoch 3/15\n",
            "Average training loss: 0.42489313605156814\n",
            "Accuracy: 0.7392739273927392 \n",
            "Accuracy over subgroups: [0.38095238 0.7983871  0.79775281 0.66666667] \n",
            "Worst Group Accuracy: 0.38095238095238093\n",
            "Epoch 4/15\n",
            "Average training loss: 0.3468688147311861\n",
            "Accuracy: 0.7491749174917491 \n",
            "Accuracy over subgroups: [0.5        0.81081081 0.73076923 0.68253968] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 5/15\n",
            "Average training loss: 0.26301669668067584\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [0.77272727 0.88028169 0.84146341 0.57894737] \n",
            "Worst Group Accuracy: 0.5789473684210527\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2249365005303513\n",
            "Accuracy: 0.801980198019802 \n",
            "Accuracy over subgroups: [0.5        0.91082803 0.81538462 0.6031746 ] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 7/15\n",
            "Average training loss: 0.18463050861927596\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.8125     0.97902098 0.77647059 0.54237288] \n",
            "Worst Group Accuracy: 0.5423728813559322\n",
            "Epoch 8/15\n",
            "Average training loss: 0.17213083227927034\n",
            "Accuracy: 0.7623762376237624 \n",
            "Accuracy over subgroups: [0.30769231 0.80555556 0.78723404 0.71153846] \n",
            "Worst Group Accuracy: 0.3076923076923077\n",
            "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 9/15\n",
            "Average training loss: 0.10961059607904065\n",
            "Accuracy: 0.8481848184818482 \n",
            "Accuracy over subgroups: [0.72727273 0.89440994 0.84210526 0.74545455] \n",
            "Worst Group Accuracy: 0.7272727272727273\n",
            "Epoch 10/15\n",
            "Average training loss: 0.05981863404370167\n",
            "Accuracy: 0.8481848184818482 \n",
            "Accuracy over subgroups: [0.54545455 0.89677419 0.8875     0.71929825] \n",
            "Worst Group Accuracy: 0.5454545454545454\n",
            "Epoch 11/15\n",
            "Average training loss: 0.03248010404323312\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.45       0.87820513 0.87804878 0.64444444] \n",
            "Worst Group Accuracy: 0.45\n",
            "Epoch 12/15\n",
            "Average training loss: 0.021721015049313955\n",
            "Accuracy: 0.8679867986798679 \n",
            "Accuracy over subgroups: [0.81818182 0.94155844 0.89333333 0.66666667] \n",
            "Worst Group Accuracy: 0.6666666666666666\n",
            "Epoch 00012: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 13/15\n",
            "Average training loss: 0.018729684631001543\n",
            "Accuracy: 0.8382838283828383 \n",
            "Accuracy over subgroups: [0.61111111 0.84415584 0.8961039  0.81481481] \n",
            "Worst Group Accuracy: 0.6111111111111112\n",
            "Epoch 14/15\n",
            "Average training loss: 0.012509287747723813\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.6875     0.84210526 0.91666667 0.68627451] \n",
            "Worst Group Accuracy: 0.6862745098039216\n",
            "Epoch 15/15\n",
            "Average training loss: 0.010572829797059636\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.4        0.82993197 0.88636364 0.83018868] \n",
            "Worst Group Accuracy: 0.4\n",
            "Epoch 00015: reducing learning rate of group 0 to 4.0000e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lastly We evaluate model performance"
      ],
      "metadata": {
        "id": "ZYpAh47-7Qb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Performance on Test Set"
      ],
      "metadata": {
        "id": "jqL4pnBH8gG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spaghetti code-esque way to get imgs and labels for entire test set\n",
        "accuracies = test(test_loader, model, verbose=False)\n",
        "\n",
        "print(f'spiculated benign accuracy: {accuracies[1]:.3f}')\n",
        "print(f'unspiculated benign accuracy: {accuracies[2]:.3f}')\n",
        "print(f'spiculated malignant accuracy: {accuracies[3]:.3f}')\n",
        "print(f'unspiculated malignant accuracy: {accuracies[4]:.3f}')\n",
        "\n",
        "print(f'Total accuracy: {accuracies[0]:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLmZBVdP8b1s",
        "outputId": "3a69576b-2b99-4fd7-fd8c-b5d7a31898a0"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spiculated benign accuracy: 0.905\n",
            "unspiculated benign accuracy: 0.869\n",
            "spiculated malignant accuracy: 0.941\n",
            "unspiculated malignant accuracy: 0.778\n",
            "Total accuracy: 0.882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##saving model for gdro"
      ],
      "metadata": {
        "id": "svZh_gEhgvqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_path = os.path.join('/content', 'LIDC_GDRO', 'weights')\n",
        "# torch.save(model.state_dict(), weight_path) #saves weights in file called weights"
      ],
      "metadata": {
        "id": "qQc2J3mrgyTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = testModel(device=DEVICE, pretrained=False, freeze=True) #model with gradients frozen \n",
        "model.load_state_dict(torch.load(weight_path, map_location=\"cuda:0\")) #loads it in\n",
        "model.model.fc = nn.Sequential(\n",
        "        nn.Linear(in_features=512, out_features=36, bias=True, device=DEVICE),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(p=0.5, inplace=False),\n",
        "        # nn.Linear(in_features=36, out_features=36, bias=True, device=DEVICE),\n",
        "        # nn.ReLU(inplace=True),\n",
        "        # nn.Dropout(p=0.5, inplace=False),\n",
        "        nn.Linear(in_features=36, out_features=2, bias=True, device=DEVICE)\n",
        "        # nn.Linear(in_features=36, out_features=1, bias=True, device=device)\n",
        "      )\n",
        "\n",
        "for layer in model.model.fc:\n",
        "  if hasattr(layer, 'weight'):\n",
        "    nn.init.xavier_uniform_(layer.weight)"
      ],
      "metadata": {
        "id": "PuYyCCF9g2To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = GDROLossAlt(model,torch.nn.CrossEntropyLoss(),1, 4) \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)#lr=0.001, weight_decay=0.005)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=2, verbose=True)"
      ],
      "metadata": {
        "id": "QeS9OYqqhn6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run of 30 test"
      ],
      "metadata": {
        "id": "_VAPWFg9DaGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "for run in range(1,16):\n",
        "  model = testModel(device=DEVICE, pretrained=True, freeze=False)\n",
        "  loss_fn = ERMLoss(model,torch.nn.CrossEntropyLoss(),{}, subclassed=True) #torch.nn.functional.binary_cross_entropy_with_logits\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.005)#lr=0.001, weight_decay=0.005)\n",
        "  scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=2, verbose=True)\n",
        "\n",
        "  epochs = 15#40\n",
        "  for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    train(train_loader, model, loss_fn, optimizer, verbose=True)\n",
        "    accuracies = test(val_loader, model, verbose=True)\n",
        "    scheduler.step(min(accuracies[1:]))\n",
        "\n",
        "  all_test_imgs = marked_benign+unmarked_benign+marked_malignant+unmarked_malignant\n",
        "  all_labels = torch.tensor([0 for _ in marked_benign+unmarked_benign]+[1 for _ in marked_malignant+unmarked_malignant], device=DEVICE)\n",
        "\n",
        "\n",
        "  print(f'spiculated benign accuracy: {get_sensitivity(model, marked_benign, 0):.3f}')\n",
        "  print(f'unspiculated benign accuracy: {get_sensitivity(model, unmarked_benign, 0):.3f}')\n",
        "  print(f'spiculated malignant accuracy: {get_sensitivity(model, marked_malignant, 1):.3f}')\n",
        "  print(f'unspiculated malignant accuracy: {get_sensitivity(model, unmarked_malignant, 1):.3f}')\n",
        "\n",
        "  print(f'Total accuracy: {get_sensitivity(model, all_test_imgs, all_labels, label_tensor=True):.3f}')\n",
        "  accuracies.append((get_sensitivity(model, marked_benign, 0),\n",
        "                     get_sensitivity(model, unmarked_benign, 0),\n",
        "                     get_sensitivity(model, marked_malignant, 1),\n",
        "                     get_sensitivity(model, unmarked_malignant, 1),\n",
        "                     get_sensitivity(model, all_test_imgs, all_labels, label_tensor=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "On1AuFGsDZxV",
        "outputId": "3799848c-889a-4603-84a7-358a2b3f1cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "Average training loss: 0.4821816821893056\n",
            "cv accuracy 0.7899999618530273\n",
            "Epoch 2/15\n",
            "Average training loss: 0.3447404861450195\n",
            "cv accuracy 0.8499999642372131\n",
            "Epoch 3/15\n",
            "Average training loss: 0.2742716550827026\n",
            "cv accuracy 0.7949999570846558\n",
            "Epoch 4/15\n",
            "Average training loss: 0.24979658193058438\n",
            "cv accuracy 0.699999988079071\n",
            "Epoch 5/15\n",
            "Average training loss: 0.23685321178701188\n",
            "cv accuracy 0.7949999570846558\n",
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 6/15\n",
            "Average training loss: 0.15020877454015943\n",
            "cv accuracy 0.8499999642372131\n",
            "Epoch 7/15\n",
            "Average training loss: 0.07932834037476116\n",
            "cv accuracy 0.8050000071525574\n",
            "Epoch 8/15\n",
            "Average training loss: 0.05756882085568375\n",
            "cv accuracy 0.7949999570846558\n",
            "Epoch 00008: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 9/15\n",
            "Average training loss: 0.032509107370343474\n",
            "cv accuracy 0.8799999952316284\n",
            "Epoch 10/15\n",
            "Average training loss: 0.02420295670421587\n",
            "cv accuracy 0.8299999833106995\n",
            "Epoch 11/15\n",
            "Average training loss: 0.01455915453326371\n",
            "cv accuracy 0.8449999690055847\n",
            "Epoch 12/15\n",
            "Average training loss: 0.011794510162952873\n",
            "cv accuracy 0.7799999713897705\n",
            "Epoch 00012: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 13/15\n",
            "Average training loss: 0.007293305390824874\n",
            "cv accuracy 0.8399999737739563\n",
            "Epoch 14/15\n",
            "Average training loss: 0.00872464899180664\n",
            "cv accuracy 0.7799999713897705\n",
            "Epoch 15/15\n",
            "Average training loss: 0.009176691370602284\n",
            "cv accuracy 0.8299999833106995\n",
            "Epoch 00015: reducing learning rate of group 0 to 8.0000e-07.\n",
            "spiculated benign accuracy: 0.810\n",
            "unspiculated benign accuracy: 0.848\n",
            "spiculated malignant accuracy: 0.866\n",
            "unspiculated malignant accuracy: 0.702\n",
            "Total accuracy: 0.823\n",
            "Epoch 1/15\n",
            "Average training loss: 0.6210956454277039\n",
            "cv accuracy 0.8199999928474426\n",
            "Epoch 2/15\n",
            "Average training loss: 0.3498178909222285\n",
            "cv accuracy 0.7699999809265137\n",
            "Epoch 3/15\n",
            "Average training loss: 0.27547374698850846\n",
            "cv accuracy 0.8100000023841858\n",
            "Epoch 4/15\n",
            "Average training loss: 0.2368752741151386\n",
            "cv accuracy 0.8050000071525574\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 5/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-385-84258ebfe7ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# train(train_spic_loader, model, loss_fn, optimizer, verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LIDC_GDRO/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, verbose)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_acc = list(map(lambda x:x[-1], accuracies))"
      ],
      "metadata": {
        "id": "aDK6p__uIjeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(total_acc)/len(total_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw-7G5JdIw6Y",
        "outputId": "315cca4b-f18b-4e3b-d3b9-000f4c87d81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8286, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = list(map(lambda x:(float(i) for i in x), accuracies))"
      ],
      "metadata": {
        "id": "HF0WKGhZJUXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(accuracies, columns = ['marked_benign', 'unmarked_benign', 'marked_malignant', 'unmarked_malignant', 'entire'])"
      ],
      "metadata": {
        "id": "-LtVK8rqIyj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gV0ZtZ7ZI5Pd",
        "outputId": "f8d49f85-ea0a-402b-fca2-ea2f93bbabd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   marked_benign  unmarked_benign  marked_malignant  unmarked_malignant  \\\n",
              "0       0.761905         0.882759          0.829268            0.754386   \n",
              "1       0.714286         0.848276          0.878049            0.789474   \n",
              "2       0.666667         0.868966          0.792683            0.684211   \n",
              "3       0.809524         0.868966          0.841463            0.771930   \n",
              "4       0.714286         0.882759          0.865854            0.754386   \n",
              "\n",
              "     entire  \n",
              "0  0.836066  \n",
              "1  0.836066  \n",
              "2  0.800000  \n",
              "3  0.839344  \n",
              "4  0.842623  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85212d84-5702-4ba2-b1d5-2a1c3c236365\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marked_benign</th>\n",
              "      <th>unmarked_benign</th>\n",
              "      <th>marked_malignant</th>\n",
              "      <th>unmarked_malignant</th>\n",
              "      <th>entire</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.882759</td>\n",
              "      <td>0.829268</td>\n",
              "      <td>0.754386</td>\n",
              "      <td>0.836066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.848276</td>\n",
              "      <td>0.878049</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.836066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.868966</td>\n",
              "      <td>0.792683</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.868966</td>\n",
              "      <td>0.841463</td>\n",
              "      <td>0.771930</td>\n",
              "      <td>0.839344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.882759</td>\n",
              "      <td>0.865854</td>\n",
              "      <td>0.754386</td>\n",
              "      <td>0.842623</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85212d84-5702-4ba2-b1d5-2a1c3c236365')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85212d84-5702-4ba2-b1d5-2a1c3c236365 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85212d84-5702-4ba2-b1d5-2a1c3c236365');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('cnn_erm_accuracies.csv')"
      ],
      "metadata": {
        "id": "yEnoVvURI7dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot = df.boxplot(column=['marked_benign', 'unmarked_benign', 'marked_malignant', 'unmarked_malignant', 'entire'], figsize = (10,10))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "fADDGXegdvPU",
        "outputId": "52c6be7e-c6c8-4d3b-9ba9-2d36c73244f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GDRO Model Performance"
      ],
      "metadata": {
        "id": "eHUrwYMILlEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_accuracies = []\n",
        "for run in range(1,16):\n",
        "  model = testModel(device=DEVICE, pretrained=True, freeze=False)\n",
        "\n",
        "  loss_fn = GDROLossAlt(model,torch.nn.CrossEntropyLoss(),0.1,4) #torch.nn.functional.binary_cross_entropy_with_logits\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.005)#lr=0.001, weight_decay=0.005)\n",
        "  scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=2, verbose=True)\n",
        "  \n",
        "  epochs = 15#40\n",
        "  for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    train(train_loader, model, loss_fn, optimizer, verbose=True)\n",
        "    accuracies = test(val_loader, model, verbose=True)\n",
        "    scheduler.step(min(accuracies[1:]))\n",
        "\n",
        "  accuracies = test(test_loader, model, verbose=False)\n",
        "\n",
        "\n",
        "  print(f'spiculated benign accuracy: {accuracies[1]:.3f}')\n",
        "  print(f'unspiculated benign accuracy: {accuracies[2]:.3f}')\n",
        "  print(f'spiculated malignant accuracy: {accuracies[3]:.3f}')\n",
        "  print(f'unspiculated malignant accuracy: {accuracies[4]:.3f}')\n",
        "\n",
        "  print(f'Total accuracy: {accuracies[0]:.3f}')\n",
        "  all_accuracies.append(accuracies)"
      ],
      "metadata": {
        "id": "diyXOH-bdyjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5762572f-b991-4e0a-eaff-3b1c2acd1831"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "Average training loss: 0.7473343881693754\n",
            "Accuracy: 0.7425742574257426 \n",
            "Accuracy over subgroups: [0.69230769 0.75362319 0.81818182 0.625     ] \n",
            "Worst Group Accuracy: 0.625\n",
            "Epoch 2/15\n",
            "Average training loss: 0.5080896406011148\n",
            "Accuracy: 0.8316831683168316 \n",
            "Accuracy over subgroups: [0.82352941 0.88888889 0.84269663 0.66037736] \n",
            "Worst Group Accuracy: 0.660377358490566\n",
            "Epoch 3/15\n",
            "Average training loss: 0.4438486668196591\n",
            "Accuracy: 0.768976897689769 \n",
            "Accuracy over subgroups: [0.57894737 0.8343949  0.77108434 0.61363636] \n",
            "Worst Group Accuracy: 0.5789473684210527\n",
            "Epoch 4/15\n",
            "Average training loss: 0.35409449616616423\n",
            "Accuracy: 0.759075907590759 \n",
            "Accuracy over subgroups: [0.64705882 0.73825503 0.82352941 0.75      ] \n",
            "Worst Group Accuracy: 0.6470588235294118\n",
            "Epoch 5/15\n",
            "Average training loss: 0.2873728302392093\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.70588235 0.8943662  0.59782609 0.73076923] \n",
            "Worst Group Accuracy: 0.5978260869565217\n",
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 6/15\n",
            "Average training loss: 0.201508144763383\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.41666667 0.87421384 0.83333333 0.63333333] \n",
            "Worst Group Accuracy: 0.4166666666666667\n",
            "Epoch 7/15\n",
            "Average training loss: 0.14668550426987084\n",
            "Accuracy: 0.7887788778877888 \n",
            "Accuracy over subgroups: [0.5        0.78378378 0.88372093 0.74509804] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 8/15\n",
            "Average training loss: 0.11310458157888868\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.6        0.88275862 0.86021505 0.67272727] \n",
            "Worst Group Accuracy: 0.6\n",
            "Epoch 00008: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 9/15\n",
            "Average training loss: 0.08936642398211089\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.35294118 0.86875    0.82432432 0.78846154] \n",
            "Worst Group Accuracy: 0.35294117647058826\n",
            "Epoch 10/15\n",
            "Average training loss: 0.07614080607891083\n",
            "Accuracy: 0.7854785478547854 \n",
            "Accuracy over subgroups: [0.55555556 0.78767123 0.88888889 0.67346939] \n",
            "Worst Group Accuracy: 0.5555555555555556\n",
            "Epoch 11/15\n",
            "Average training loss: 0.07441588262604042\n",
            "Accuracy: 0.801980198019802 \n",
            "Accuracy over subgroups: [0.33333333 0.84722222 0.82278481 0.76470588] \n",
            "Worst Group Accuracy: 0.3333333333333333\n",
            "Epoch 00011: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 12/15\n",
            "Average training loss: 0.060665535952218554\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.47368421 0.90070922 0.86813187 0.73076923] \n",
            "Worst Group Accuracy: 0.47368421052631576\n",
            "Epoch 13/15\n",
            "Average training loss: 0.06755305974828926\n",
            "Accuracy: 0.8316831683168316 \n",
            "Accuracy over subgroups: [0.6        0.89312977 0.86538462 0.67241379] \n",
            "Worst Group Accuracy: 0.6\n",
            "Epoch 14/15\n",
            "Average training loss: 0.05179566064510833\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.5625     0.84415584 0.90277778 0.70491803] \n",
            "Worst Group Accuracy: 0.5625\n",
            "Epoch 00014: reducing learning rate of group 0 to 8.0000e-07.\n",
            "Epoch 15/15\n",
            "Average training loss: 0.06256409450857477\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.41666667 0.8447205  0.90666667 0.74545455] \n",
            "Worst Group Accuracy: 0.4166666666666667\n",
            "spiculated benign accuracy: 0.931\n",
            "unspiculated benign accuracy: 0.864\n",
            "spiculated malignant accuracy: 0.860\n",
            "unspiculated malignant accuracy: 0.741\n",
            "Total accuracy: 0.846\n",
            "Epoch 1/15\n",
            "Average training loss: 0.8956536813215776\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.53333333 0.76388889 0.93406593 0.73584906] \n",
            "Worst Group Accuracy: 0.5333333333333333\n",
            "Epoch 2/15\n",
            "Average training loss: 0.47703922472216864\n",
            "Accuracy: 0.735973597359736 \n",
            "Accuracy over subgroups: [0.33333333 0.69620253 0.94366197 0.73584906] \n",
            "Worst Group Accuracy: 0.3333333333333333\n",
            "Epoch 3/15\n",
            "Average training loss: 0.38016762042587454\n",
            "Accuracy: 0.7722772277227723 \n",
            "Accuracy over subgroups: [0.5625     0.75949367 0.82716049 0.79166667] \n",
            "Worst Group Accuracy: 0.5625\n",
            "Epoch 4/15\n",
            "Average training loss: 0.3187356388027018\n",
            "Accuracy: 0.7128712871287128 \n",
            "Accuracy over subgroups: [0.5        0.88321168 0.6741573  0.44262295] \n",
            "Worst Group Accuracy: 0.4426229508196721\n",
            "Epoch 5/15\n",
            "Average training loss: 0.2465407441962849\n",
            "Accuracy: 0.768976897689769 \n",
            "Accuracy over subgroups: [0.55555556 0.8707483  0.66292135 0.70689655] \n",
            "Worst Group Accuracy: 0.5555555555555556\n",
            "Epoch 6/15\n",
            "Average training loss: 0.22977240959351714\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [1.         0.88461538 0.6835443  0.68627451] \n",
            "Worst Group Accuracy: 0.6835443037974683\n",
            "Epoch 7/15\n",
            "Average training loss: 0.18869908374141564\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.47368421 0.89051095 0.77777778 0.78947368] \n",
            "Worst Group Accuracy: 0.47368421052631576\n",
            "Epoch 8/15\n",
            "Average training loss: 0.13908841748806564\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.5        0.89583333 0.80898876 0.67857143] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 9/15\n",
            "Average training loss: 0.12399225851351564\n",
            "Accuracy: 0.8382838283828383 \n",
            "Accuracy over subgroups: [0.66666667 0.87272727 0.79761905 0.84615385] \n",
            "Worst Group Accuracy: 0.6666666666666666\n",
            "Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 10/15\n",
            "Average training loss: 0.07213988294824958\n",
            "Accuracy: 0.858085808580858 \n",
            "Accuracy over subgroups: [0.5        0.87301587 0.8952381  0.83333333] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 11/15\n",
            "Average training loss: 0.03815301571210677\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.5        0.81045752 0.93243243 0.76666667] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 12/15\n",
            "Average training loss: 0.01743123722686009\n",
            "Accuracy: 0.8514851485148515 \n",
            "Accuracy over subgroups: [0.85714286 0.89583333 0.87096774 0.69230769] \n",
            "Worst Group Accuracy: 0.6923076923076923\n",
            "Epoch 13/15\n",
            "Average training loss: 0.018392447869039395\n",
            "Accuracy: 0.8514851485148515 \n",
            "Accuracy over subgroups: [0.70588235 0.92361111 0.84810127 0.73015873] \n",
            "Worst Group Accuracy: 0.7058823529411765\n",
            "Epoch 14/15\n",
            "Average training loss: 0.01255390834888782\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.8        0.94339623 0.78313253 0.52941176] \n",
            "Worst Group Accuracy: 0.5294117647058824\n",
            "Epoch 15/15\n",
            "Average training loss: 0.007718716438499872\n",
            "Accuracy: 0.8316831683168316 \n",
            "Accuracy over subgroups: [0.64705882 0.86842105 0.88235294 0.69387755] \n",
            "Worst Group Accuracy: 0.6470588235294118\n",
            "spiculated benign accuracy: 0.810\n",
            "unspiculated benign accuracy: 0.836\n",
            "spiculated malignant accuracy: 0.779\n",
            "unspiculated malignant accuracy: 0.744\n",
            "Total accuracy: 0.803\n",
            "Epoch 1/15\n",
            "Average training loss: 0.8388120545582338\n",
            "Accuracy: 0.7128712871287128 \n",
            "Accuracy over subgroups: [0.66666667 0.94771242 0.60493827 0.22222222] \n",
            "Worst Group Accuracy: 0.2222222222222222\n",
            "Epoch 2/15\n",
            "Average training loss: 0.6615430089560422\n",
            "Accuracy: 0.7491749174917491 \n",
            "Accuracy over subgroups: [0.25       0.67808219 0.93939394 0.66      ] \n",
            "Worst Group Accuracy: 0.25\n",
            "Epoch 3/15\n",
            "Average training loss: 0.4496543522585522\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.38095238 0.82666667 0.88297872 0.71052632] \n",
            "Worst Group Accuracy: 0.38095238095238093\n",
            "Epoch 4/15\n",
            "Average training loss: 0.43080146543004294\n",
            "Accuracy: 0.7788778877887789 \n",
            "Accuracy over subgroups: [0.3125     0.6993865  1.         0.88709677] \n",
            "Worst Group Accuracy: 0.3125\n",
            "Epoch 5/15\n",
            "Average training loss: 0.3328506966883486\n",
            "Accuracy: 0.7953795379537953 \n",
            "Accuracy over subgroups: [0.70588235 0.86330935 0.79245283 0.6097561 ] \n",
            "Worst Group Accuracy: 0.6097560975609756\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2880086885257201\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.45       0.70866142 0.87628866 0.81355932] \n",
            "Worst Group Accuracy: 0.45\n",
            "Epoch 7/15\n",
            "Average training loss: 0.22330528429963373\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.41176471 0.82352941 0.83544304 0.96296296] \n",
            "Worst Group Accuracy: 0.4117647058823529\n",
            "Epoch 8/15\n",
            "Average training loss: 0.17976173487576572\n",
            "Accuracy: 0.7854785478547854 \n",
            "Accuracy over subgroups: [0.44444444 0.82638889 0.82417582 0.72      ] \n",
            "Worst Group Accuracy: 0.4444444444444444\n",
            "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 9/15\n",
            "Average training loss: 0.14121261645447125\n",
            "Accuracy: 0.7788778877887789 \n",
            "Accuracy over subgroups: [0.44444444 0.90140845 0.77173913 0.56862745] \n",
            "Worst Group Accuracy: 0.4444444444444444\n",
            "Epoch 10/15\n",
            "Average training loss: 0.082248461432755\n",
            "Accuracy: 0.7887788778877888 \n",
            "Accuracy over subgroups: [0.41666667 0.81632653 0.81553398 0.73170732] \n",
            "Worst Group Accuracy: 0.4166666666666667\n",
            "Epoch 11/15\n",
            "Average training loss: 0.049877183300189\n",
            "Accuracy: 0.7821782178217822 \n",
            "Accuracy over subgroups: [0.23076923 0.84246575 0.81818182 0.71641791] \n",
            "Worst Group Accuracy: 0.23076923076923078\n",
            "Epoch 00011: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 12/15\n",
            "Average training loss: 0.037237685321914876\n",
            "Accuracy: 0.8316831683168316 \n",
            "Accuracy over subgroups: [0.47058824 0.87581699 0.89534884 0.70212766] \n",
            "Worst Group Accuracy: 0.47058823529411764\n",
            "Epoch 13/15\n",
            "Average training loss: 0.02687071964398704\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.54545455 0.89051095 0.83908046 0.68421053] \n",
            "Worst Group Accuracy: 0.5454545454545454\n",
            "Epoch 14/15\n",
            "Average training loss: 0.023189882123419506\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.23529412 0.85294118 0.8877551  0.75      ] \n",
            "Worst Group Accuracy: 0.23529411764705882\n",
            "Epoch 00014: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 15/15\n",
            "Average training loss: 0.0189644890117713\n",
            "Accuracy: 0.8547854785478548 \n",
            "Accuracy over subgroups: [0.54545455 0.94405594 0.825      0.75362319] \n",
            "Worst Group Accuracy: 0.5454545454545454\n",
            "spiculated benign accuracy: 0.833\n",
            "unspiculated benign accuracy: 0.880\n",
            "spiculated malignant accuracy: 0.815\n",
            "unspiculated malignant accuracy: 0.768\n",
            "Total accuracy: 0.836\n",
            "Epoch 1/15\n",
            "Average training loss: 0.8602123673666607\n",
            "Accuracy: 0.7821782178217822 \n",
            "Accuracy over subgroups: [0.64705882 0.66666667 0.90909091 0.93548387] \n",
            "Worst Group Accuracy: 0.6470588235294118\n",
            "Epoch 2/15\n",
            "Average training loss: 0.5210729458115317\n",
            "Accuracy: 0.7854785478547854 \n",
            "Accuracy over subgroups: [0.375      0.77631579 0.91139241 0.75      ] \n",
            "Worst Group Accuracy: 0.375\n",
            "Epoch 3/15\n",
            "Average training loss: 0.43564513461156323\n",
            "Accuracy: 0.7953795379537953 \n",
            "Accuracy over subgroups: [0.26666667 0.82835821 0.87234043 0.73333333] \n",
            "Worst Group Accuracy: 0.26666666666666666\n",
            "Epoch 4/15\n",
            "Average training loss: 0.3738391673700376\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [0.5        0.85714286 0.83333333 0.71428571] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 5/15\n",
            "Average training loss: 0.25959769500927493\n",
            "Accuracy: 0.8316831683168316 \n",
            "Accuracy over subgroups: [0.78571429 0.85714286 0.8372093  0.78571429] \n",
            "Worst Group Accuracy: 0.7857142857142857\n",
            "Epoch 6/15\n",
            "Average training loss: 0.22186566279693085\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.38888889 0.83571429 0.8452381  0.7704918 ] \n",
            "Worst Group Accuracy: 0.3888888888888889\n",
            "Epoch 7/15\n",
            "Average training loss: 0.16868000155822796\n",
            "Accuracy: 0.8811881188118812 \n",
            "Accuracy over subgroups: [0.76470588 0.89041096 0.93333333 0.8       ] \n",
            "Worst Group Accuracy: 0.7647058823529411\n",
            "Epoch 8/15\n",
            "Average training loss: 0.13479598645459523\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.8        0.83088235 0.85555556 0.79032258] \n",
            "Worst Group Accuracy: 0.7903225806451613\n",
            "Epoch 9/15\n",
            "Average training loss: 0.10098313675685362\n",
            "Accuracy: 0.8448844884488449 \n",
            "Accuracy over subgroups: [0.6        0.8707483  0.8875     0.78688525] \n",
            "Worst Group Accuracy: 0.6\n",
            "Epoch 10/15\n",
            "Average training loss: 0.0690060203302313\n",
            "Accuracy: 0.8448844884488449 \n",
            "Accuracy over subgroups: [0.65       0.91489362 0.86170213 0.6875    ] \n",
            "Worst Group Accuracy: 0.65\n",
            "Epoch 11/15\n",
            "Average training loss: 0.05787878716364503\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.46666667 0.86805556 0.9        0.7037037 ] \n",
            "Worst Group Accuracy: 0.4666666666666667\n",
            "Epoch 00011: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 12/15\n",
            "Average training loss: 0.04151801870797168\n",
            "Accuracy: 0.8877887788778878 \n",
            "Accuracy over subgroups: [0.73333333 0.93197279 0.89772727 0.79245283] \n",
            "Worst Group Accuracy: 0.7333333333333333\n",
            "Epoch 13/15\n",
            "Average training loss: 0.02513199602253735\n",
            "Accuracy: 0.8712871287128713 \n",
            "Accuracy over subgroups: [0.6875     0.90909091 0.92857143 0.68292683] \n",
            "Worst Group Accuracy: 0.6829268292682927\n",
            "Epoch 14/15\n",
            "Average training loss: 0.02024288405664265\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.69230769 0.81528662 0.86585366 0.84313725] \n",
            "Worst Group Accuracy: 0.6923076923076923\n",
            "Epoch 00014: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 15/15\n",
            "Average training loss: 0.017306045502085577\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.45       0.85211268 0.89534884 0.70909091] \n",
            "Worst Group Accuracy: 0.45\n",
            "spiculated benign accuracy: 0.682\n",
            "unspiculated benign accuracy: 0.824\n",
            "spiculated malignant accuracy: 0.864\n",
            "unspiculated malignant accuracy: 0.650\n",
            "Total accuracy: 0.790\n",
            "Epoch 1/15\n",
            "Average training loss: 0.6534147939898751\n",
            "Accuracy: 0.7227722772277227 \n",
            "Accuracy over subgroups: [0.46153846 0.6442953  0.88764045 0.73076923] \n",
            "Worst Group Accuracy: 0.46153846153846156\n",
            "Epoch 2/15\n",
            "Average training loss: 0.4800676012581045\n",
            "Accuracy: 0.7458745874587459 \n",
            "Accuracy over subgroups: [0.6        0.7080292  0.85858586 0.67307692] \n",
            "Worst Group Accuracy: 0.6\n",
            "Epoch 3/15\n",
            "Average training loss: 0.38992544399066403\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.42857143 0.80392157 0.85714286 0.78846154] \n",
            "Worst Group Accuracy: 0.42857142857142855\n",
            "Epoch 4/15\n",
            "Average training loss: 0.34813016788526013\n",
            "Accuracy: 0.7722772277227723 \n",
            "Accuracy over subgroups: [0.5        0.81118881 0.77108434 0.75409836] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 5/15\n",
            "Average training loss: 0.29688357121565123\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.24       0.83333333 0.78651685 0.80392157] \n",
            "Worst Group Accuracy: 0.24\n",
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 6/15\n",
            "Average training loss: 0.21125087277455765\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.4375     0.84868421 0.80519481 0.75862069] \n",
            "Worst Group Accuracy: 0.4375\n",
            "Epoch 7/15\n",
            "Average training loss: 0.15403517623516647\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [0.25       0.84172662 0.88372093 0.77419355] \n",
            "Worst Group Accuracy: 0.25\n",
            "Epoch 8/15\n",
            "Average training loss: 0.11260982221839103\n",
            "Accuracy: 0.8217821782178217 \n",
            "Accuracy over subgroups: [0.47826087 0.88125    0.828125   0.78571429] \n",
            "Worst Group Accuracy: 0.4782608695652174\n",
            "Epoch 00008: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 9/15\n",
            "Average training loss: 0.09460105941715566\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [0.58333333 0.81944444 0.81395349 0.81967213] \n",
            "Worst Group Accuracy: 0.5833333333333334\n",
            "Epoch 10/15\n",
            "Average training loss: 0.08327915003015236\n",
            "Accuracy: 0.8514851485148515 \n",
            "Accuracy over subgroups: [0.5        0.90140845 0.8902439  0.78688525] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 11/15\n",
            "Average training loss: 0.06209308933466673\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.11111111 0.9047619  0.86842105 0.79032258] \n",
            "Worst Group Accuracy: 0.1111111111111111\n",
            "Epoch 00011: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 12/15\n",
            "Average training loss: 0.05290516351603649\n",
            "Accuracy: 0.768976897689769 \n",
            "Accuracy over subgroups: [0.40909091 0.8057554  0.84946237 0.67346939] \n",
            "Worst Group Accuracy: 0.4090909090909091\n",
            "Epoch 13/15\n",
            "Average training loss: 0.05093571666458791\n",
            "Accuracy: 0.8184818481848185 \n",
            "Accuracy over subgroups: [0.5        0.86624204 0.82758621 0.73333333] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 14/15\n",
            "Average training loss: 0.048959484260359946\n",
            "Accuracy: 0.8844884488448845 \n",
            "Accuracy over subgroups: [0.71428571 0.92907801 0.9125     0.80327869] \n",
            "Worst Group Accuracy: 0.7142857142857143\n",
            "Epoch 15/15\n",
            "Average training loss: 0.05748081056993793\n",
            "Accuracy: 0.8481848184818482 \n",
            "Accuracy over subgroups: [0.41176471 0.84415584 0.92682927 0.88      ] \n",
            "Worst Group Accuracy: 0.4117647058823529\n",
            "spiculated benign accuracy: 0.783\n",
            "unspiculated benign accuracy: 0.856\n",
            "spiculated malignant accuracy: 0.949\n",
            "unspiculated malignant accuracy: 0.815\n",
            "Total accuracy: 0.866\n",
            "Epoch 1/15\n",
            "Average training loss: 0.7927807684649121\n",
            "Accuracy: 0.7887788778877888 \n",
            "Accuracy over subgroups: [0.65217391 0.82876712 0.75       0.83333333] \n",
            "Worst Group Accuracy: 0.6521739130434783\n",
            "Epoch 2/15\n",
            "Average training loss: 0.4736455184492198\n",
            "Accuracy: 0.759075907590759 \n",
            "Accuracy over subgroups: [0.5        0.66906475 0.87356322 0.88135593] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 3/15\n",
            "Average training loss: 0.4167320836674083\n",
            "Accuracy: 0.8184818481848185 \n",
            "Accuracy over subgroups: [0.4        0.81203008 0.92473118 0.74626866] \n",
            "Worst Group Accuracy: 0.4\n",
            "Epoch 4/15\n",
            "Average training loss: 0.3505677655339241\n",
            "Accuracy: 0.6732673267326733 \n",
            "Accuracy over subgroups: [0.73684211 0.92028986 0.42528736 0.44067797] \n",
            "Worst Group Accuracy: 0.42528735632183906\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 5/15\n",
            "Average training loss: 0.2851923087781126\n",
            "Accuracy: 0.768976897689769 \n",
            "Accuracy over subgroups: [0.53846154 0.80769231 0.7654321  0.71698113] \n",
            "Worst Group Accuracy: 0.5384615384615384\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2020102141594345\n",
            "Accuracy: 0.7755775577557755 \n",
            "Accuracy over subgroups: [0.55555556 0.81632653 0.8021978  0.66071429] \n",
            "Worst Group Accuracy: 0.5555555555555556\n",
            "Epoch 7/15\n",
            "Average training loss: 0.15904280526394193\n",
            "Accuracy: 0.801980198019802 \n",
            "Accuracy over subgroups: [0.54545455 0.85314685 0.82978723 0.67272727] \n",
            "Worst Group Accuracy: 0.5454545454545454\n",
            "Epoch 00007: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 8/15\n",
            "Average training loss: 0.13206936918537726\n",
            "Accuracy: 0.8217821782178217 \n",
            "Accuracy over subgroups: [0.44444444 0.82550336 0.91208791 0.72222222] \n",
            "Worst Group Accuracy: 0.4444444444444444\n",
            "Epoch 9/15\n",
            "Average training loss: 0.12333008900962093\n",
            "Accuracy: 0.768976897689769 \n",
            "Accuracy over subgroups: [0.5        0.79220779 0.86842105 0.66666667] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 10/15\n",
            "Average training loss: 0.10943652714856646\n",
            "Accuracy: 0.7458745874587459 \n",
            "Accuracy over subgroups: [0.45       0.77564103 0.83561644 0.64814815] \n",
            "Worst Group Accuracy: 0.45\n",
            "Epoch 00010: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 11/15\n",
            "Average training loss: 0.09248481724749912\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.36363636 0.8880597  0.83962264 0.67307692] \n",
            "Worst Group Accuracy: 0.36363636363636365\n",
            "Epoch 12/15\n",
            "Average training loss: 0.09811050004579804\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.71428571 0.88275862 0.76344086 0.74137931] \n",
            "Worst Group Accuracy: 0.7142857142857143\n",
            "Epoch 13/15\n",
            "Average training loss: 0.08631051365624774\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.57142857 0.83333333 0.85393258 0.62745098] \n",
            "Worst Group Accuracy: 0.5714285714285714\n",
            "Epoch 14/15\n",
            "Average training loss: 0.08063404600728642\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.35       0.89051095 0.78947368 0.74509804] \n",
            "Worst Group Accuracy: 0.35\n",
            "Epoch 15/15\n",
            "Average training loss: 0.08265768994831225\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.52941176 0.83221477 0.88       0.77419355] \n",
            "Worst Group Accuracy: 0.5294117647058824\n",
            "Epoch 00015: reducing learning rate of group 0 to 8.0000e-07.\n",
            "spiculated benign accuracy: 0.870\n",
            "unspiculated benign accuracy: 0.803\n",
            "spiculated malignant accuracy: 0.833\n",
            "unspiculated malignant accuracy: 0.794\n",
            "Total accuracy: 0.813\n",
            "Epoch 1/15\n",
            "Average training loss: 0.7748560837723992\n",
            "Accuracy: 0.7623762376237624 \n",
            "Accuracy over subgroups: [0.625      0.77931034 0.86206897 0.6       ] \n",
            "Worst Group Accuracy: 0.6\n",
            "Epoch 2/15\n",
            "Average training loss: 0.4705501131036065\n",
            "Accuracy: 0.8217821782178217 \n",
            "Accuracy over subgroups: [0.5        0.8343949  0.89873418 0.73684211] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 3/15\n",
            "Average training loss: 0.39429520443081856\n",
            "Accuracy: 0.7458745874587459 \n",
            "Accuracy over subgroups: [0.55555556 0.83950617 0.66666667 0.61904762] \n",
            "Worst Group Accuracy: 0.5555555555555556\n",
            "Epoch 4/15\n",
            "Average training loss: 0.33238491449843754\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.54545455 0.76470588 0.94871795 0.80327869] \n",
            "Worst Group Accuracy: 0.5454545454545454\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 5/15\n",
            "Average training loss: 0.25702562217007985\n",
            "Accuracy: 0.7953795379537953 \n",
            "Accuracy over subgroups: [0.5625     0.8313253  0.80821918 0.72916667] \n",
            "Worst Group Accuracy: 0.5625\n",
            "Epoch 6/15\n",
            "Average training loss: 0.22255658527666872\n",
            "Accuracy: 0.7755775577557755 \n",
            "Accuracy over subgroups: [0.35       0.82580645 0.81176471 0.72093023] \n",
            "Worst Group Accuracy: 0.35\n",
            "Epoch 7/15\n",
            "Average training loss: 0.1685408309779384\n",
            "Accuracy: 0.7821782178217822 \n",
            "Accuracy over subgroups: [0.5        0.8951049  0.73626374 0.65306122] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 00007: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 8/15\n",
            "Average training loss: 0.12018712796270847\n",
            "Accuracy: 0.8316831683168316 \n",
            "Accuracy over subgroups: [0.4        0.90839695 0.86868687 0.70689655] \n",
            "Worst Group Accuracy: 0.4\n",
            "Epoch 9/15\n",
            "Average training loss: 0.11495286649601026\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.53333333 0.81632653 0.80851064 0.59574468] \n",
            "Worst Group Accuracy: 0.5333333333333333\n",
            "Epoch 10/15\n",
            "Average training loss: 0.0936626499010758\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.21052632 0.80136986 0.85393258 0.71428571] \n",
            "Worst Group Accuracy: 0.21052631578947367\n",
            "Epoch 00010: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 11/15\n",
            "Average training loss: 0.09326003551144492\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [0.47058824 0.83536585 0.84810127 0.74418605] \n",
            "Worst Group Accuracy: 0.47058823529411764\n",
            "Epoch 12/15\n",
            "Average training loss: 0.0843820148570971\n",
            "Accuracy: 0.8217821782178217 \n",
            "Accuracy over subgroups: [0.3125     0.87586207 0.81818182 0.83333333] \n",
            "Worst Group Accuracy: 0.3125\n",
            "Epoch 13/15\n",
            "Average training loss: 0.07538257877935063\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.46666667 0.88666667 0.83908046 0.7254902 ] \n",
            "Worst Group Accuracy: 0.4666666666666667\n",
            "Epoch 00013: reducing learning rate of group 0 to 8.0000e-07.\n",
            "Epoch 14/15\n",
            "Average training loss: 0.08044228567318483\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.55       0.83333333 0.89534884 0.74576271] \n",
            "Worst Group Accuracy: 0.55\n",
            "Epoch 15/15\n",
            "Average training loss: 0.08089261442761529\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [0.47619048 0.83098592 0.88764045 0.74509804] \n",
            "Worst Group Accuracy: 0.47619047619047616\n",
            "spiculated benign accuracy: 0.737\n",
            "unspiculated benign accuracy: 0.809\n",
            "spiculated malignant accuracy: 0.861\n",
            "unspiculated malignant accuracy: 0.709\n",
            "Total accuracy: 0.800\n",
            "Epoch 1/15\n",
            "Average training loss: 0.9146768613295122\n",
            "Accuracy: 0.7458745874587459 \n",
            "Accuracy over subgroups: [0.75       0.7345679  0.86075949 0.61111111] \n",
            "Worst Group Accuracy: 0.6111111111111112\n",
            "Epoch 2/15\n",
            "Average training loss: 0.49533836340362375\n",
            "Accuracy: 0.7524752475247525 \n",
            "Accuracy over subgroups: [0.41176471 0.77536232 0.86046512 0.64516129] \n",
            "Worst Group Accuracy: 0.4117647058823529\n",
            "Epoch 3/15\n",
            "Average training loss: 0.43196105889298697\n",
            "Accuracy: 0.7392739273927392 \n",
            "Accuracy over subgroups: [0.46153846 0.73584906 0.79746835 0.82051282] \n",
            "Worst Group Accuracy: 0.46153846153846156\n",
            "Epoch 4/15\n",
            "Average training loss: 0.3421695391562852\n",
            "Accuracy: 0.7788778877887789 \n",
            "Accuracy over subgroups: [0.30769231 0.83216783 0.82352941 0.69354839] \n",
            "Worst Group Accuracy: 0.3076923076923077\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 5/15\n",
            "Average training loss: 0.2794215100055391\n",
            "Accuracy: 0.7557755775577558 \n",
            "Accuracy over subgroups: [0.41176471 0.8013245  0.76744186 0.71428571] \n",
            "Worst Group Accuracy: 0.4117647058823529\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2037313197824088\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.41176471 0.82608696 0.88888889 0.70689655] \n",
            "Worst Group Accuracy: 0.4117647058823529\n",
            "Epoch 7/15\n",
            "Average training loss: 0.15537871132520112\n",
            "Accuracy: 0.8448844884488449 \n",
            "Accuracy over subgroups: [0.73684211 0.88571429 0.88636364 0.71428571] \n",
            "Worst Group Accuracy: 0.7142857142857143\n",
            "Epoch 8/15\n",
            "Average training loss: 0.12117424192415042\n",
            "Accuracy: 0.8382838283828383 \n",
            "Accuracy over subgroups: [0.69230769 0.89102564 0.87179487 0.67857143] \n",
            "Worst Group Accuracy: 0.6785714285714286\n",
            "Epoch 9/15\n",
            "Average training loss: 0.09252567013556307\n",
            "Accuracy: 0.8448844884488449 \n",
            "Accuracy over subgroups: [0.8        0.84962406 0.87368421 0.8       ] \n",
            "Worst Group Accuracy: 0.8\n",
            "Epoch 10/15\n",
            "Average training loss: 0.06388317243280736\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.44444444 0.90510949 0.9        0.73469388] \n",
            "Worst Group Accuracy: 0.4444444444444444\n",
            "Epoch 11/15\n",
            "Average training loss: 0.05193590592931618\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.71428571 0.88157895 0.90361446 0.57407407] \n",
            "Worst Group Accuracy: 0.5740740740740741\n",
            "Epoch 12/15\n",
            "Average training loss: 0.04012375940907408\n",
            "Accuracy: 0.8217821782178217 \n",
            "Accuracy over subgroups: [0.51851852 0.81751825 0.90697674 0.8490566 ] \n",
            "Worst Group Accuracy: 0.5185185185185185\n",
            "Epoch 00012: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 13/15\n",
            "Average training loss: 0.019624418039298194\n",
            "Accuracy: 0.8316831683168316 \n",
            "Accuracy over subgroups: [0.35294118 0.90909091 0.87951807 0.67346939] \n",
            "Worst Group Accuracy: 0.35294117647058826\n",
            "Epoch 14/15\n",
            "Average training loss: 0.016895770021206277\n",
            "Accuracy: 0.7953795379537953 \n",
            "Accuracy over subgroups: [0.35294118 0.875      0.85       0.62962963] \n",
            "Worst Group Accuracy: 0.35294117647058826\n",
            "Epoch 15/15\n",
            "Average training loss: 0.011340877893169156\n",
            "Accuracy: 0.8547854785478548 \n",
            "Accuracy over subgroups: [0.11764706 0.89928058 0.95348837 0.81967213] \n",
            "Worst Group Accuracy: 0.11764705882352941\n",
            "Epoch 00015: reducing learning rate of group 0 to 4.0000e-06.\n",
            "spiculated benign accuracy: 0.846\n",
            "unspiculated benign accuracy: 0.833\n",
            "spiculated malignant accuracy: 0.840\n",
            "unspiculated malignant accuracy: 0.738\n",
            "Total accuracy: 0.816\n",
            "Epoch 1/15\n",
            "Average training loss: 0.7938403541391547\n",
            "Accuracy: 0.7326732673267327 \n",
            "Accuracy over subgroups: [0.52380952 0.73469388 0.87179487 0.61403509] \n",
            "Worst Group Accuracy: 0.5238095238095238\n",
            "Epoch 2/15\n",
            "Average training loss: 0.559877220202576\n",
            "Accuracy: 0.7854785478547854 \n",
            "Accuracy over subgroups: [0.47058824 0.67375887 0.94845361 0.89583333] \n",
            "Worst Group Accuracy: 0.47058823529411764\n",
            "Epoch 3/15\n",
            "Average training loss: 0.45479224960912357\n",
            "Accuracy: 0.7623762376237624 \n",
            "Accuracy over subgroups: [0.55555556 0.78169014 0.89041096 0.64285714] \n",
            "Worst Group Accuracy: 0.5555555555555556\n",
            "Epoch 4/15\n",
            "Average training loss: 0.3895687955346974\n",
            "Accuracy: 0.7821782178217822 \n",
            "Accuracy over subgroups: [0.66666667 0.8137931  0.81176471 0.68852459] \n",
            "Worst Group Accuracy: 0.6666666666666666\n",
            "Epoch 5/15\n",
            "Average training loss: 0.3195183981548656\n",
            "Accuracy: 0.7755775577557755 \n",
            "Accuracy over subgroups: [0.76923077 0.94405594 0.67816092 0.51666667] \n",
            "Worst Group Accuracy: 0.5166666666666667\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2525015761229125\n",
            "Accuracy: 0.801980198019802 \n",
            "Accuracy over subgroups: [0.64285714 0.83783784 0.80597015 0.75675676] \n",
            "Worst Group Accuracy: 0.6428571428571429\n",
            "Epoch 7/15\n",
            "Average training loss: 0.2129970843141729\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.6        0.82432432 0.92941176 0.78181818] \n",
            "Worst Group Accuracy: 0.6\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 8/15\n",
            "Average training loss: 0.15502041273496367\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [0.63157895 0.8707483  0.77922078 0.73333333] \n",
            "Worst Group Accuracy: 0.631578947368421\n",
            "Epoch 9/15\n",
            "Average training loss: 0.09439899611540815\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.66666667 0.85806452 0.82716049 0.83673469] \n",
            "Worst Group Accuracy: 0.6666666666666666\n",
            "Epoch 10/15\n",
            "Average training loss: 0.06318032309751619\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.57142857 0.89542484 0.87951807 0.62264151] \n",
            "Worst Group Accuracy: 0.5714285714285714\n",
            "Epoch 00010: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 11/15\n",
            "Average training loss: 0.05937932033769109\n",
            "Accuracy: 0.8217821782178217 \n",
            "Accuracy over subgroups: [0.54545455 0.89473684 0.75       0.78571429] \n",
            "Worst Group Accuracy: 0.5454545454545454\n",
            "Epoch 12/15\n",
            "Average training loss: 0.05513190169056708\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.81818182 0.86363636 0.85135135 0.703125  ] \n",
            "Worst Group Accuracy: 0.703125\n",
            "Epoch 13/15\n",
            "Average training loss: 0.04161965758116408\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.75       0.90441176 0.7826087  0.78181818] \n",
            "Worst Group Accuracy: 0.75\n",
            "Epoch 14/15\n",
            "Average training loss: 0.029407933671874078\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.5625     0.83571429 0.85882353 0.75806452] \n",
            "Worst Group Accuracy: 0.5625\n",
            "Epoch 15/15\n",
            "Average training loss: 0.028147167145189913\n",
            "Accuracy: 0.8415841584158416 \n",
            "Accuracy over subgroups: [0.75       0.88965517 0.74285714 0.85526316] \n",
            "Worst Group Accuracy: 0.7428571428571429\n",
            "spiculated benign accuracy: 0.846\n",
            "unspiculated benign accuracy: 0.880\n",
            "spiculated malignant accuracy: 0.848\n",
            "unspiculated malignant accuracy: 0.723\n",
            "Total accuracy: 0.846\n",
            "Epoch 1/15\n",
            "Average training loss: 0.9964112226258625\n",
            "Accuracy: 0.7755775577557755 \n",
            "Accuracy over subgroups: [0.68421053 0.80794702 0.83529412 0.60416667] \n",
            "Worst Group Accuracy: 0.6041666666666666\n",
            "Epoch 2/15\n",
            "Average training loss: 0.5013997879895297\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.66666667 0.76388889 0.78888889 0.75925926] \n",
            "Worst Group Accuracy: 0.6666666666666666\n",
            "Epoch 3/15\n",
            "Average training loss: 0.41031414744528855\n",
            "Accuracy: 0.7194719471947195 \n",
            "Accuracy over subgroups: [0.72222222 0.75       0.7173913  0.64912281] \n",
            "Worst Group Accuracy: 0.6491228070175439\n",
            "Epoch 4/15\n",
            "Average training loss: 0.38315870646726\n",
            "Accuracy: 0.7788778877887789 \n",
            "Accuracy over subgroups: [0.72727273 0.79577465 0.80412371 0.69811321] \n",
            "Worst Group Accuracy: 0.6981132075471698\n",
            "Epoch 5/15\n",
            "Average training loss: 0.27823155745863914\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.78571429 0.91823899 0.74157303 0.65853659] \n",
            "Worst Group Accuracy: 0.6585365853658537\n",
            "Epoch 6/15\n",
            "Average training loss: 0.23355772617188367\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [0.61538462 0.89171975 0.78666667 0.65517241] \n",
            "Worst Group Accuracy: 0.6153846153846154\n",
            "Epoch 7/15\n",
            "Average training loss: 0.17633270827884023\n",
            "Accuracy: 0.8514851485148515 \n",
            "Accuracy over subgroups: [0.71428571 0.85897436 0.90217391 0.75609756] \n",
            "Worst Group Accuracy: 0.7142857142857143\n",
            "Epoch 8/15\n",
            "Average training loss: 0.15115969983691518\n",
            "Accuracy: 0.8646864686468647 \n",
            "Accuracy over subgroups: [0.58333333 0.87919463 0.91358025 0.81967213] \n",
            "Worst Group Accuracy: 0.5833333333333334\n",
            "Epoch 9/15\n",
            "Average training loss: 0.1254254248501225\n",
            "Accuracy: 0.7623762376237624 \n",
            "Accuracy over subgroups: [0.33333333 0.70253165 0.94666667 0.82692308] \n",
            "Worst Group Accuracy: 0.3333333333333333\n",
            "Epoch 10/15\n",
            "Average training loss: 0.11438660183921456\n",
            "Accuracy: 0.8481848184818482 \n",
            "Accuracy over subgroups: [0.69230769 0.92957746 0.83495146 0.66666667] \n",
            "Worst Group Accuracy: 0.6666666666666666\n",
            "Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 11/15\n",
            "Average training loss: 0.07193810721351342\n",
            "Accuracy: 0.8679867986798679 \n",
            "Accuracy over subgroups: [0.81818182 0.88028169 0.9        0.81355932] \n",
            "Worst Group Accuracy: 0.8135593220338984\n",
            "Epoch 12/15\n",
            "Average training loss: 0.02745385793969035\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [0.88888889 0.80136986 0.87804878 0.72727273] \n",
            "Worst Group Accuracy: 0.7272727272727273\n",
            "Epoch 13/15\n",
            "Average training loss: 0.01657684010834518\n",
            "Accuracy: 0.8250825082508251 \n",
            "Accuracy over subgroups: [0.6        0.8627451  0.84810127 0.75      ] \n",
            "Worst Group Accuracy: 0.6\n",
            "Epoch 14/15\n",
            "Average training loss: 0.01076157999076796\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.64285714 0.84172662 0.8        0.8       ] \n",
            "Worst Group Accuracy: 0.6428571428571429\n",
            "Epoch 00014: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 15/15\n",
            "Average training loss: 0.007172762096161023\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.83333333 0.87837838 0.8255814  0.60784314] \n",
            "Worst Group Accuracy: 0.6078431372549019\n",
            "spiculated benign accuracy: 0.947\n",
            "unspiculated benign accuracy: 0.870\n",
            "spiculated malignant accuracy: 0.918\n",
            "unspiculated malignant accuracy: 0.810\n",
            "Total accuracy: 0.882\n",
            "Epoch 1/15\n",
            "Average training loss: 0.7494112713770433\n",
            "Accuracy: 0.7821782178217822 \n",
            "Accuracy over subgroups: [0.625      0.84285714 0.8375     0.62686567] \n",
            "Worst Group Accuracy: 0.625\n",
            "Epoch 2/15\n",
            "Average training loss: 0.4851642000404271\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [0.61111111 0.76666667 0.93670886 0.78571429] \n",
            "Worst Group Accuracy: 0.6111111111111112\n",
            "Epoch 3/15\n",
            "Average training loss: 0.38165092739191925\n",
            "Accuracy: 0.7722772277227723 \n",
            "Accuracy over subgroups: [0.61538462 0.86486486 0.76190476 0.5862069 ] \n",
            "Worst Group Accuracy: 0.5862068965517241\n",
            "Epoch 4/15\n",
            "Average training loss: 0.33372706886042247\n",
            "Accuracy: 0.8415841584158416 \n",
            "Accuracy over subgroups: [0.75       0.84       0.84       0.87096774] \n",
            "Worst Group Accuracy: 0.75\n",
            "Epoch 5/15\n",
            "Average training loss: 0.27074689451943745\n",
            "Accuracy: 0.7128712871287128 \n",
            "Accuracy over subgroups: [0.29411765 0.76190476 0.77027027 0.64615385] \n",
            "Worst Group Accuracy: 0.29411764705882354\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2338738583705642\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.61538462 0.92810458 0.7721519  0.62068966] \n",
            "Worst Group Accuracy: 0.6153846153846154\n",
            "Epoch 7/15\n",
            "Average training loss: 0.22617770595984024\n",
            "Accuracy: 0.7755775577557755 \n",
            "Accuracy over subgroups: [0.30769231 0.80689655 0.84444444 0.69090909] \n",
            "Worst Group Accuracy: 0.3076923076923077\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 8/15\n",
            "Average training loss: 0.1287267248738896\n",
            "Accuracy: 0.7887788778877888 \n",
            "Accuracy over subgroups: [0.5        0.86029412 0.82051282 0.69565217] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 9/15\n",
            "Average training loss: 0.08042308857495134\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [0.25       0.83443709 0.9125     0.75      ] \n",
            "Worst Group Accuracy: 0.25\n",
            "Epoch 10/15\n",
            "Average training loss: 0.047863558823750776\n",
            "Accuracy: 0.7854785478547854 \n",
            "Accuracy over subgroups: [0.30434783 0.81679389 0.93181818 0.68852459] \n",
            "Worst Group Accuracy: 0.30434782608695654\n",
            "Epoch 00010: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 11/15\n",
            "Average training loss: 0.03920823430896483\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [0.63157895 0.87857143 0.81927711 0.67213115] \n",
            "Worst Group Accuracy: 0.631578947368421\n",
            "Epoch 12/15\n",
            "Average training loss: 0.027886533707549625\n",
            "Accuracy: 0.8382838283828383 \n",
            "Accuracy over subgroups: [0.42105263 0.86577181 0.93478261 0.72093023] \n",
            "Worst Group Accuracy: 0.42105263157894735\n",
            "Epoch 13/15\n",
            "Average training loss: 0.020481285808438606\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.33333333 0.88888889 0.84782609 0.69387755] \n",
            "Worst Group Accuracy: 0.3333333333333333\n",
            "Epoch 00013: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 14/15\n",
            "Average training loss: 0.019007537397556007\n",
            "Accuracy: 0.8118811881188119 \n",
            "Accuracy over subgroups: [0.42857143 0.86111111 0.94594595 0.671875  ] \n",
            "Worst Group Accuracy: 0.42857142857142855\n",
            "Epoch 15/15\n",
            "Average training loss: 0.019010958198288627\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.66666667 0.87417219 0.8902439  0.68852459] \n",
            "Worst Group Accuracy: 0.6666666666666666\n",
            "spiculated benign accuracy: 0.800\n",
            "unspiculated benign accuracy: 0.851\n",
            "spiculated malignant accuracy: 0.802\n",
            "unspiculated malignant accuracy: 0.667\n",
            "Total accuracy: 0.803\n",
            "Epoch 1/15\n",
            "Average training loss: 0.7995296594771472\n",
            "Accuracy: 0.7326732673267327 \n",
            "Accuracy over subgroups: [0.28571429 0.77857143 0.77108434 0.72881356] \n",
            "Worst Group Accuracy: 0.2857142857142857\n",
            "Epoch 2/15\n",
            "Average training loss: 0.4961820983073928\n",
            "Accuracy: 0.7722772277227723 \n",
            "Accuracy over subgroups: [0.57142857 0.80136986 0.86842105 0.64179104] \n",
            "Worst Group Accuracy: 0.5714285714285714\n",
            "Epoch 3/15\n",
            "Average training loss: 0.4030500372702425\n",
            "Accuracy: 0.7821782178217822 \n",
            "Accuracy over subgroups: [0.46153846 0.82781457 0.8        0.69387755] \n",
            "Worst Group Accuracy: 0.46153846153846156\n",
            "Epoch 4/15\n",
            "Average training loss: 0.33729212764989247\n",
            "Accuracy: 0.7524752475247525 \n",
            "Accuracy over subgroups: [0.27777778 0.83098592 0.79775281 0.62962963] \n",
            "Worst Group Accuracy: 0.2777777777777778\n",
            "Epoch 5/15\n",
            "Average training loss: 0.2776960554448041\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [0.41666667 0.91666667 0.78021978 0.56818182] \n",
            "Worst Group Accuracy: 0.4166666666666667\n",
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2099932154471224\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.4        0.83453237 0.825      0.63768116] \n",
            "Worst Group Accuracy: 0.4\n",
            "Epoch 7/15\n",
            "Average training loss: 0.15434061143208633\n",
            "Accuracy: 0.7722772277227723 \n",
            "Accuracy over subgroups: [0.4        0.84076433 0.86585366 0.51020408] \n",
            "Worst Group Accuracy: 0.4\n",
            "Epoch 8/15\n",
            "Average training loss: 0.11228004775264046\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [0.33333333 0.87121212 0.86021505 0.73333333] \n",
            "Worst Group Accuracy: 0.3333333333333333\n",
            "Epoch 00008: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 9/15\n",
            "Average training loss: 0.09819273100319234\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.35294118 0.84313725 0.97647059 0.72916667] \n",
            "Worst Group Accuracy: 0.35294117647058826\n",
            "Epoch 10/15\n",
            "Average training loss: 0.1065065771849318\n",
            "Accuracy: 0.8316831683168316 \n",
            "Accuracy over subgroups: [0.5        0.86111111 0.94444444 0.66666667] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 11/15\n",
            "Average training loss: 0.08819802689620039\n",
            "Accuracy: 0.8448844884488449 \n",
            "Accuracy over subgroups: [0.33333333 0.85987261 0.9010989  0.7826087 ] \n",
            "Worst Group Accuracy: 0.3333333333333333\n",
            "Epoch 00011: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 12/15\n",
            "Average training loss: 0.07966983098198067\n",
            "Accuracy: 0.8547854785478548 \n",
            "Accuracy over subgroups: [0.54545455 0.85119048 0.90361446 0.85365854] \n",
            "Worst Group Accuracy: 0.5454545454545454\n",
            "Epoch 13/15\n",
            "Average training loss: 0.07365741521458734\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [0.44444444 0.78832117 0.92631579 0.75471698] \n",
            "Worst Group Accuracy: 0.4444444444444444\n",
            "Epoch 14/15\n",
            "Average training loss: 0.06895128908482465\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.44444444 0.82706767 0.90291262 0.79310345] \n",
            "Worst Group Accuracy: 0.4444444444444444\n",
            "Epoch 00014: reducing learning rate of group 0 to 8.0000e-07.\n",
            "Epoch 15/15\n",
            "Average training loss: 0.06845474420962008\n",
            "Accuracy: 0.858085808580858 \n",
            "Accuracy over subgroups: [0.63636364 0.82208589 0.96341463 0.85106383] \n",
            "Worst Group Accuracy: 0.6363636363636364\n",
            "spiculated benign accuracy: 0.708\n",
            "unspiculated benign accuracy: 0.901\n",
            "spiculated malignant accuracy: 0.933\n",
            "unspiculated malignant accuracy: 0.683\n",
            "Total accuracy: 0.852\n",
            "Epoch 1/15\n",
            "Average training loss: 0.7498866637999361\n",
            "Accuracy: 0.6996699669966997 \n",
            "Accuracy over subgroups: [0.57142857 0.55555556 0.96296296 0.72580645] \n",
            "Worst Group Accuracy: 0.5555555555555556\n",
            "Epoch 2/15\n",
            "Average training loss: 0.4947990517724644\n",
            "Accuracy: 0.8184818481848185 \n",
            "Accuracy over subgroups: [1.         0.77333333 0.88043478 0.8245614 ] \n",
            "Worst Group Accuracy: 0.7733333333333333\n",
            "Epoch 3/15\n",
            "Average training loss: 0.38940585336901923\n",
            "Accuracy: 0.759075907590759 \n",
            "Accuracy over subgroups: [0.64705882 0.75342466 0.82894737 0.71875   ] \n",
            "Worst Group Accuracy: 0.6470588235294118\n",
            "Epoch 4/15\n",
            "Average training loss: 0.3344400999220935\n",
            "Accuracy: 0.8415841584158416 \n",
            "Accuracy over subgroups: [0.75       0.85350318 0.84946237 0.8       ] \n",
            "Worst Group Accuracy: 0.75\n",
            "Epoch 5/15\n",
            "Average training loss: 0.2461492664773356\n",
            "Accuracy: 0.8481848184818482 \n",
            "Accuracy over subgroups: [0.83333333 0.92948718 0.75       0.76744186] \n",
            "Worst Group Accuracy: 0.75\n",
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 6/15\n",
            "Average training loss: 0.18262347866865722\n",
            "Accuracy: 0.7920792079207921 \n",
            "Accuracy over subgroups: [0.71428571 0.85915493 0.71428571 0.76785714] \n",
            "Worst Group Accuracy: 0.7142857142857143\n",
            "Epoch 7/15\n",
            "Average training loss: 0.11645530113442377\n",
            "Accuracy: 0.7920792079207921 \n",
            "Accuracy over subgroups: [0.5        0.8490566  0.76470588 0.734375  ] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 8/15\n",
            "Average training loss: 0.08162636292928999\n",
            "Accuracy: 0.8382838283828383 \n",
            "Accuracy over subgroups: [0.38461538 0.85810811 0.85714286 0.8627451 ] \n",
            "Worst Group Accuracy: 0.38461538461538464\n",
            "Epoch 00008: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 9/15\n",
            "Average training loss: 0.05792346787215634\n",
            "Accuracy: 0.7953795379537953 \n",
            "Accuracy over subgroups: [0.82608696 0.79470199 0.7972973  0.78181818] \n",
            "Worst Group Accuracy: 0.7818181818181819\n",
            "Epoch 10/15\n",
            "Average training loss: 0.04670288240198384\n",
            "Accuracy: 0.7920792079207921 \n",
            "Accuracy over subgroups: [0.77777778 0.88157895 0.74666667 0.62068966] \n",
            "Worst Group Accuracy: 0.6206896551724138\n",
            "Epoch 11/15\n",
            "Average training loss: 0.042623956984078344\n",
            "Accuracy: 0.7722772277227723 \n",
            "Accuracy over subgroups: [0.54545455 0.82394366 0.79775281 0.68      ] \n",
            "Worst Group Accuracy: 0.5454545454545454\n",
            "Epoch 12/15\n",
            "Average training loss: 0.03115469689311629\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.72222222 0.84931507 0.81395349 0.75471698] \n",
            "Worst Group Accuracy: 0.7222222222222222\n",
            "Epoch 00012: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 13/15\n",
            "Average training loss: 0.025813770374621858\n",
            "Accuracy: 0.8151815181518152 \n",
            "Accuracy over subgroups: [0.79166667 0.82608696 0.84337349 0.75862069] \n",
            "Worst Group Accuracy: 0.7586206896551724\n",
            "Epoch 14/15\n",
            "Average training loss: 0.03268193351951512\n",
            "Accuracy: 0.7986798679867987 \n",
            "Accuracy over subgroups: [0.8        0.75333333 0.88372093 0.78846154] \n",
            "Worst Group Accuracy: 0.7533333333333333\n",
            "Epoch 15/15\n",
            "Average training loss: 0.02677252668548714\n",
            "Accuracy: 0.7887788778877888 \n",
            "Accuracy over subgroups: [0.9        0.85897436 0.74418605 0.62745098] \n",
            "Worst Group Accuracy: 0.6274509803921569\n",
            "Epoch 00015: reducing learning rate of group 0 to 8.0000e-07.\n",
            "spiculated benign accuracy: 0.778\n",
            "unspiculated benign accuracy: 0.855\n",
            "spiculated malignant accuracy: 0.910\n",
            "unspiculated malignant accuracy: 0.702\n",
            "Total accuracy: 0.836\n",
            "Epoch 1/15\n",
            "Average training loss: 0.7274426072835922\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.4        0.66666667 0.94565217 0.77777778] \n",
            "Worst Group Accuracy: 0.4\n",
            "Epoch 2/15\n",
            "Average training loss: 0.5270166498693553\n",
            "Accuracy: 0.8481848184818482 \n",
            "Accuracy over subgroups: [0.69230769 0.88435374 0.88405797 0.78688525] \n",
            "Worst Group Accuracy: 0.6923076923076923\n",
            "Epoch 3/15\n",
            "Average training loss: 0.4063459455289624\n",
            "Accuracy: 0.7854785478547854 \n",
            "Accuracy over subgroups: [0.42105263 0.73381295 0.93406593 0.7962963 ] \n",
            "Worst Group Accuracy: 0.42105263157894735\n",
            "Epoch 4/15\n",
            "Average training loss: 0.4074451672759923\n",
            "Accuracy: 0.759075907590759 \n",
            "Accuracy over subgroups: [0.41176471 0.90184049 0.65384615 0.55555556] \n",
            "Worst Group Accuracy: 0.4117647058823529\n",
            "Epoch 5/15\n",
            "Average training loss: 0.30210745774886827\n",
            "Accuracy: 0.7788778877887789 \n",
            "Accuracy over subgroups: [0.38888889 0.75       0.92045455 0.75471698] \n",
            "Worst Group Accuracy: 0.3888888888888889\n",
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2371803650801832\n",
            "Accuracy: 0.8052805280528053 \n",
            "Accuracy over subgroups: [0.41176471 0.85135135 0.85542169 0.72727273] \n",
            "Worst Group Accuracy: 0.4117647058823529\n",
            "Epoch 7/15\n",
            "Average training loss: 0.17005443759262562\n",
            "Accuracy: 0.7854785478547854 \n",
            "Accuracy over subgroups: [0.5        0.84285714 0.83695652 0.62711864] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 8/15\n",
            "Average training loss: 0.13916878334500574\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.64285714 0.90196078 0.81927711 0.71698113] \n",
            "Worst Group Accuracy: 0.6428571428571429\n",
            "Epoch 00008: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 9/15\n",
            "Average training loss: 0.10071354257789525\n",
            "Accuracy: 0.8481848184818482 \n",
            "Accuracy over subgroups: [0.30769231 0.86363636 0.9223301  0.8       ] \n",
            "Worst Group Accuracy: 0.3076923076923077\n",
            "Epoch 10/15\n",
            "Average training loss: 0.08966876236213879\n",
            "Accuracy: 0.8382838283828383 \n",
            "Accuracy over subgroups: [0.625      0.87857143 0.89772727 0.71186441] \n",
            "Worst Group Accuracy: 0.625\n",
            "Epoch 11/15\n",
            "Average training loss: 0.08354108484292572\n",
            "Accuracy: 0.7821782178217822 \n",
            "Accuracy over subgroups: [0.30434783 0.78571429 0.8630137  0.86792453] \n",
            "Worst Group Accuracy: 0.30434782608695654\n",
            "Epoch 00011: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 12/15\n",
            "Average training loss: 0.06670129019767046\n",
            "Accuracy: 0.858085808580858 \n",
            "Accuracy over subgroups: [0.42857143 0.89115646 0.90243902 0.81666667] \n",
            "Worst Group Accuracy: 0.42857142857142855\n",
            "Epoch 13/15\n",
            "Average training loss: 0.07248160776428202\n",
            "Accuracy: 0.858085808580858 \n",
            "Accuracy over subgroups: [0.45454545 0.8627451  0.95238095 0.78181818] \n",
            "Worst Group Accuracy: 0.45454545454545453\n",
            "Epoch 14/15\n",
            "Average training loss: 0.06260870862752199\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.4        0.86451613 0.89010989 0.68085106] \n",
            "Worst Group Accuracy: 0.4\n",
            "Epoch 00014: reducing learning rate of group 0 to 8.0000e-07.\n",
            "Epoch 15/15\n",
            "Average training loss: 0.0649343573234298\n",
            "Accuracy: 0.801980198019802 \n",
            "Accuracy over subgroups: [0.27272727 0.85620915 0.88       0.75471698] \n",
            "Worst Group Accuracy: 0.2727272727272727\n",
            "spiculated benign accuracy: 0.864\n",
            "unspiculated benign accuracy: 0.824\n",
            "spiculated malignant accuracy: 0.895\n",
            "unspiculated malignant accuracy: 0.831\n",
            "Total accuracy: 0.846\n",
            "Epoch 1/15\n",
            "Average training loss: 0.8639954477548599\n",
            "Accuracy: 0.7656765676567657 \n",
            "Accuracy over subgroups: [0.8        0.85815603 0.68965517 0.65      ] \n",
            "Worst Group Accuracy: 0.65\n",
            "Epoch 2/15\n",
            "Average training loss: 0.5230367447842251\n",
            "Accuracy: 0.7557755775577558 \n",
            "Accuracy over subgroups: [0.42857143 0.80555556 0.82716049 0.625     ] \n",
            "Worst Group Accuracy: 0.42857142857142855\n",
            "Epoch 3/15\n",
            "Average training loss: 0.4323957826603543\n",
            "Accuracy: 0.7887788778877888 \n",
            "Accuracy over subgroups: [0.41176471 0.72058824 0.8989899  0.88235294] \n",
            "Worst Group Accuracy: 0.4117647058823529\n",
            "Epoch 4/15\n",
            "Average training loss: 0.40285478600046853\n",
            "Accuracy: 0.7557755775577558 \n",
            "Accuracy over subgroups: [0.55555556 0.79617834 0.77647059 0.65116279] \n",
            "Worst Group Accuracy: 0.5555555555555556\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 5/15\n",
            "Average training loss: 0.3107187798754735\n",
            "Accuracy: 0.7722772277227723 \n",
            "Accuracy over subgroups: [0.47368421 0.81118881 0.82051282 0.71428571] \n",
            "Worst Group Accuracy: 0.47368421052631576\n",
            "Epoch 6/15\n",
            "Average training loss: 0.2514638849957423\n",
            "Accuracy: 0.8085808580858086 \n",
            "Accuracy over subgroups: [1.         0.84415584 0.78313253 0.71428571] \n",
            "Worst Group Accuracy: 0.7142857142857143\n",
            "Epoch 7/15\n",
            "Average training loss: 0.21021535535427657\n",
            "Accuracy: 0.7887788778877888 \n",
            "Accuracy over subgroups: [0.64285714 0.84868421 0.75308642 0.71428571] \n",
            "Worst Group Accuracy: 0.6428571428571429\n",
            "Epoch 8/15\n",
            "Average training loss: 0.15788479521870613\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.7        0.88970588 0.81609195 0.75      ] \n",
            "Worst Group Accuracy: 0.7\n",
            "Epoch 9/15\n",
            "Average training loss: 0.12512955873865972\n",
            "Accuracy: 0.8283828382838284 \n",
            "Accuracy over subgroups: [0.53333333 0.85234899 0.86746988 0.78571429] \n",
            "Worst Group Accuracy: 0.5333333333333333\n",
            "Epoch 00009: reducing learning rate of group 0 to 2.0000e-05.\n",
            "Epoch 10/15\n",
            "Average training loss: 0.0760849511928179\n",
            "Accuracy: 0.8712871287128713 \n",
            "Accuracy over subgroups: [0.6875     0.88356164 0.89534884 0.85454545] \n",
            "Worst Group Accuracy: 0.6875\n",
            "Epoch 11/15\n",
            "Average training loss: 0.06336733169684355\n",
            "Accuracy: 0.7920792079207921 \n",
            "Accuracy over subgroups: [0.31578947 0.84563758 0.92307692 0.54545455] \n",
            "Worst Group Accuracy: 0.3157894736842105\n",
            "Epoch 12/15\n",
            "Average training loss: 0.05621302889829332\n",
            "Accuracy: 0.8382838283828383 \n",
            "Accuracy over subgroups: [0.5        0.88235294 0.8902439  0.72222222] \n",
            "Worst Group Accuracy: 0.5\n",
            "Epoch 00012: reducing learning rate of group 0 to 4.0000e-06.\n",
            "Epoch 13/15\n",
            "Average training loss: 0.04530159070749174\n",
            "Accuracy: 0.7953795379537953 \n",
            "Accuracy over subgroups: [0.6875     0.85064935 0.80952381 0.63265306] \n",
            "Worst Group Accuracy: 0.6326530612244898\n",
            "Epoch 14/15\n",
            "Average training loss: 0.04889281017875129\n",
            "Accuracy: 0.834983498349835 \n",
            "Accuracy over subgroups: [0.58823529 0.90666667 0.83116883 0.72881356] \n",
            "Worst Group Accuracy: 0.5882352941176471\n",
            "Epoch 15/15\n",
            "Average training loss: 0.044302108231931925\n",
            "Accuracy: 0.8481848184818482 \n",
            "Accuracy over subgroups: [0.75       0.88235294 0.8974359  0.71428571] \n",
            "Worst Group Accuracy: 0.7142857142857143\n",
            "Epoch 00015: reducing learning rate of group 0 to 8.0000e-07.\n",
            "spiculated benign accuracy: 0.789\n",
            "unspiculated benign accuracy: 0.783\n",
            "spiculated malignant accuracy: 0.826\n",
            "unspiculated malignant accuracy: 0.708\n",
            "Total accuracy: 0.784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_acc = list(map(lambda x:x[-1], all_accuracies))\n",
        "sum(total_acc)/len(total_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExaVr_XiNbf1",
        "outputId": "0703cbd9-77e9-47e0-8b95-c3119bad1ba4"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.738851866306012"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "skV_9lrbu3Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = list(map(lambda x:(float(i) for i in x), all_accuracies))"
      ],
      "metadata": {
        "id": "G4BHL1UyNfbu"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(accuracies, columns = ['entire', 'marked_benign', 'unmarked_benign', 'marked_malignant', 'unmarked_malignant'])"
      ],
      "metadata": {
        "id": "UreqijzlNgn6"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tNJ22ivoNhs4",
        "outputId": "a315f70f-e76b-43b8-ce1c-a1c406863279"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     entire  marked_benign  unmarked_benign  marked_malignant  \\\n",
              "0  0.845902       0.931034         0.863636          0.860465   \n",
              "1  0.803279       0.809524         0.835616          0.778947   \n",
              "2  0.836066       0.833333         0.879699          0.815217   \n",
              "3  0.790164       0.681818         0.823944          0.864198   \n",
              "4  0.865574       0.782609         0.856115          0.948718   \n",
              "\n",
              "   unmarked_malignant  \n",
              "0            0.741379  \n",
              "1            0.744186  \n",
              "2            0.767857  \n",
              "3            0.650000  \n",
              "4            0.815385  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5b1654e-7b46-4ac6-b893-2800ce90aed8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entire</th>\n",
              "      <th>marked_benign</th>\n",
              "      <th>unmarked_benign</th>\n",
              "      <th>marked_malignant</th>\n",
              "      <th>unmarked_malignant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.845902</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.741379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.835616</td>\n",
              "      <td>0.778947</td>\n",
              "      <td>0.744186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.879699</td>\n",
              "      <td>0.815217</td>\n",
              "      <td>0.767857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.790164</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.823944</td>\n",
              "      <td>0.864198</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.865574</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.856115</td>\n",
              "      <td>0.948718</td>\n",
              "      <td>0.815385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5b1654e-7b46-4ac6-b893-2800ce90aed8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5b1654e-7b46-4ac6-b893-2800ce90aed8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5b1654e-7b46-4ac6-b893-2800ce90aed8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('cnn_gdro_accuracies.csv')"
      ],
      "metadata": {
        "id": "EmViwDoRNiwH"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot = df.boxplot(column=['marked_benign', 'unmarked_benign', 'marked_malignant', 'unmarked_malignant', 'entire'], figsize = (10,10))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "0gG6k4auNjzf",
        "outputId": "8031ed61-7401-49e7-8839-306fcfb796ac"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "lidc_cnn_ERM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}