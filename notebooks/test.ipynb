{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoduleDataset, SubtypedDataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import NoduleDataset, SubtypedDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Good to go!\")\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using cpu\")\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing SubtypedDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Nodule_id</th>\n",
       "      <th>malignancy</th>\n",
       "      <th>subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1197</td>\n",
       "      <td>benign</td>\n",
       "      <td>0benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1208</td>\n",
       "      <td>benign</td>\n",
       "      <td>1benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1109</td>\n",
       "      <td>benign</td>\n",
       "      <td>1benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1259</td>\n",
       "      <td>benign</td>\n",
       "      <td>0benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1050</td>\n",
       "      <td>benign</td>\n",
       "      <td>1benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Nodule_id malignancy  subtype\n",
       "0           0       1197     benign  0benign\n",
       "1           1       1208     benign  1benign\n",
       "2           2       1109     benign  1benign\n",
       "3           3       1259     benign  0benign\n",
       "4           4       1050     benign  1benign"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidc_subtyped = pd.read_csv('../data/lidc_subtyped.csv')\n",
    "lidc_subtyped.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormed(this_array, this_min = 0, this_max = 255, set_to_int = True):\n",
    "    \n",
    "    rat = (this_max - this_min)/(this_array.max() - this_array.min())\n",
    "    this_array = this_array * rat\n",
    "    this_array -= this_array.min()\n",
    "    this_array += this_min\n",
    "    if set_to_int:\n",
    "        return this_array.to(dtype= torch.int)\n",
    "    return this_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages(image_folder):\n",
    "    '''\n",
    "        Input:\n",
    "        image_folder: directory of the image files\n",
    "\n",
    "        Output:\n",
    "        m1: list of the labels encountered (1,2,4,5)\n",
    "        m2: list of binary labels encountered (benign, malignant)\n",
    "        diff: list of any nodes with discrepency to CSV labels\n",
    "\n",
    "    '''\n",
    "    \n",
    "    M_benign = []\n",
    "    L_benign = []\n",
    "    \n",
    "    M_malignant = []\n",
    "    L_malignant = []\n",
    "\n",
    "    \n",
    "\n",
    "    lidc = pd.read_csv('../data/lidc_subtyped.csv')\n",
    "    for dir1 in os.listdir(image_folder):\n",
    "  \n",
    "        if dir1 == 'Malignancy_3':\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(os.path.join(image_folder, dir1)):\n",
    "#             malignancy_orig = int(dir1[-1])\n",
    "#             m1.append(malignancy_orig)\n",
    "\n",
    "            temp_nodule_ID = file.split('.')[0]\n",
    "            subtype = lidc[lidc['Nodule_id']==int(temp_nodule_ID)]['subtype'].iloc[0] \n",
    "            \n",
    "            if subtype == '0benign':\n",
    "                image_array = M_benign\n",
    "            elif subtype == '1benign':\n",
    "                image_array = L_benign\n",
    "            elif subtype == '1malignant':\n",
    "                image_array = M_malignant\n",
    "            else:\n",
    "                image_array = L_malignant\n",
    "            \n",
    "            image = np.loadtxt(os.path.join(image_folder, dir1,file))\n",
    "            image = torch.from_numpy(image).to(DEVICE)\n",
    "            rgb_image = torch.stack((image,image,image), dim = 0)\n",
    "            rgb_image = getNormed(rgb_image)\n",
    "            rgb_image = rgb_image / 255 \n",
    "\n",
    "            image_array.append(rgb_image)\n",
    "\n",
    "\n",
    "    return M_benign, L_benign, M_malignant, L_malignant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_benign, L_benign, M_malignant, L_malignant = getImages('../data/LIDC(MaxSlices)_Nodules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of M_benign: 519, Size of L_benign: 512, \n",
      "Size of M_malignant: 430, Size of L_malignant: 202\n"
     ]
    }
   ],
   "source": [
    "print(f'''Size of M_benign: {len(M_benign)}, Size of L_benign: {len(L_benign)}, \n",
    "Size of M_malignant: {len(M_malignant)}, Size of L_malignant: {len(L_malignant)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_data = {'M_benign': (M_benign, torch.zeros(519)), \n",
    "                 'L_benign': (L_benign, torch.zeros(512)),\n",
    "                 'M_malignant': (M_malignant, torch.ones(430)),\n",
    "                 'L_malignant': (L_malignant, torch.ones(202))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SubtypedDataLoader(subclass_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for idx, b in enumerate(a):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "subclass_Dataset =  NoduleDataset(*subclass_data['L_malignant'])\n",
    "subclass_iterLoader = cycle(iter(DataLoader(subclass_Dataset, 200, shuffle=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [158]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\repos\\LIDC_GDRO\\datasets.py:50\u001b[0m, in \u001b[0;36mSubtypedDataLoader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m minibatch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iterLoader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloaders:\n\u001b[1;32m---> 50\u001b[0m     minibatch\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterLoader\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m minibatch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:569\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing DomainBeds dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_data_loader import InfiniteDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleDomainDataset:\n",
    "    N_STEPS = 5001           # Default, subclasses may override\n",
    "    CHECKPOINT_FREQ = 100    # Default, subclasses may override\n",
    "    N_WORKERS = 1 #8           # Default, subclasses may override\n",
    "    ENVIRONMENTS = None      # Subclasses should override\n",
    "    INPUT_SHAPE = None       # Subclasses should override\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.datasets[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterdLIDC(MultipleDomainDataset):\n",
    "    def __init__(self, root, environments, input_shape,\n",
    "                 num_classes):\n",
    "        super().__init__()\n",
    "        if root is None:\n",
    "            raise ValueError('Data directory not specified!')\n",
    "        \n",
    "        #hard coded: M_benign, L_benign, M_malignant, L_malignant \n",
    "        all_images = getImages(root)\n",
    "        \n",
    "        self.datasets = []\n",
    "        \n",
    "        for i in range(len(environments)):\n",
    "            images = all_images[i] \n",
    "            labels = torch.zeros(len(images)) if i < 2 else torch.ones(len(images))\n",
    "            self.datasets.append(NoduleDataset(images,labels))\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ClusterdLIDC('LIDC(MaxSlices)_Nodules',['M_benign', 'L_benign', 'M_malignant', 'L_malignant'], None, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_loaders = [InfiniteDataLoader(\n",
    "        dataset=env, #each subclass DataSet\n",
    "        weights=None, #None\n",
    "        batch_size=200,\n",
    "        num_workers=1)\n",
    "        for i, env in enumerate(datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<fast_data_loader.InfiniteDataLoader at 0x24ab8fa6830>,\n",
       " <fast_data_loader.InfiniteDataLoader at 0x24ab8fe3f40>,\n",
       " <fast_data_loader.InfiniteDataLoader at 0x24ab8f361d0>,\n",
       " <fast_data_loader.InfiniteDataLoader at 0x24ab8f371f0>]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_minibatches_iterator = zip(*train_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x24ab4c97700>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_minibatches_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1020, 0.0784, 0.0549,  ..., 0.4431, 0.4510, 0.4314],\n",
       "          [0.0941, 0.0745, 0.0706,  ..., 0.4510, 0.4275, 0.4314],\n",
       "          [0.0784, 0.0627, 0.0627,  ..., 0.4549, 0.4471, 0.4549],\n",
       "          ...,\n",
       "          [0.1294, 0.1216, 0.0706,  ..., 0.4745, 0.4784, 0.4941],\n",
       "          [0.1529, 0.1216, 0.0784,  ..., 0.4902, 0.4941, 0.4980],\n",
       "          [0.1804, 0.1137, 0.0627,  ..., 0.4980, 0.5098, 0.5137]],\n",
       "\n",
       "         [[0.1020, 0.0784, 0.0549,  ..., 0.4431, 0.4510, 0.4314],\n",
       "          [0.0941, 0.0745, 0.0706,  ..., 0.4510, 0.4275, 0.4314],\n",
       "          [0.0784, 0.0627, 0.0627,  ..., 0.4549, 0.4471, 0.4549],\n",
       "          ...,\n",
       "          [0.1294, 0.1216, 0.0706,  ..., 0.4745, 0.4784, 0.4941],\n",
       "          [0.1529, 0.1216, 0.0784,  ..., 0.4902, 0.4941, 0.4980],\n",
       "          [0.1804, 0.1137, 0.0627,  ..., 0.4980, 0.5098, 0.5137]],\n",
       "\n",
       "         [[0.1020, 0.0784, 0.0549,  ..., 0.4431, 0.4510, 0.4314],\n",
       "          [0.0941, 0.0745, 0.0706,  ..., 0.4510, 0.4275, 0.4314],\n",
       "          [0.0784, 0.0627, 0.0627,  ..., 0.4549, 0.4471, 0.4549],\n",
       "          ...,\n",
       "          [0.1294, 0.1216, 0.0706,  ..., 0.4745, 0.4784, 0.4941],\n",
       "          [0.1529, 0.1216, 0.0784,  ..., 0.4902, 0.4941, 0.4980],\n",
       "          [0.1804, 0.1137, 0.0627,  ..., 0.4980, 0.5098, 0.5137]]],\n",
       "\n",
       "\n",
       "        [[[0.8039, 0.7490, 0.7333,  ..., 0.7255, 0.6941, 0.6784],\n",
       "          [0.6118, 0.4980, 0.4863,  ..., 0.6980, 0.6745, 0.7255],\n",
       "          [0.2314, 0.1529, 0.1882,  ..., 0.7059, 0.7098, 0.7333],\n",
       "          ...,\n",
       "          [0.8824, 0.9020, 0.8510,  ..., 0.1922, 0.0980, 0.0824],\n",
       "          [0.9020, 0.8863, 0.8314,  ..., 0.1765, 0.1294, 0.1137],\n",
       "          [0.8980, 0.8784, 0.8078,  ..., 0.1529, 0.1216, 0.0549]],\n",
       "\n",
       "         [[0.8039, 0.7490, 0.7333,  ..., 0.7255, 0.6941, 0.6784],\n",
       "          [0.6118, 0.4980, 0.4863,  ..., 0.6980, 0.6745, 0.7255],\n",
       "          [0.2314, 0.1529, 0.1882,  ..., 0.7059, 0.7098, 0.7333],\n",
       "          ...,\n",
       "          [0.8824, 0.9020, 0.8510,  ..., 0.1922, 0.0980, 0.0824],\n",
       "          [0.9020, 0.8863, 0.8314,  ..., 0.1765, 0.1294, 0.1137],\n",
       "          [0.8980, 0.8784, 0.8078,  ..., 0.1529, 0.1216, 0.0549]],\n",
       "\n",
       "         [[0.8039, 0.7490, 0.7333,  ..., 0.7255, 0.6941, 0.6784],\n",
       "          [0.6118, 0.4980, 0.4863,  ..., 0.6980, 0.6745, 0.7255],\n",
       "          [0.2314, 0.1529, 0.1882,  ..., 0.7059, 0.7098, 0.7333],\n",
       "          ...,\n",
       "          [0.8824, 0.9020, 0.8510,  ..., 0.1922, 0.0980, 0.0824],\n",
       "          [0.9020, 0.8863, 0.8314,  ..., 0.1765, 0.1294, 0.1137],\n",
       "          [0.8980, 0.8784, 0.8078,  ..., 0.1529, 0.1216, 0.0549]]],\n",
       "\n",
       "\n",
       "        [[[0.0510, 0.0510, 0.0588,  ..., 0.6235, 0.6667, 0.5961],\n",
       "          [0.0549, 0.0588, 0.0667,  ..., 0.5882, 0.6392, 0.6549],\n",
       "          [0.0627, 0.0588, 0.0392,  ..., 0.5647, 0.5961, 0.6431],\n",
       "          ...,\n",
       "          [0.6431, 0.6392, 0.6627,  ..., 0.6039, 0.6824, 0.7020],\n",
       "          [0.6431, 0.6353, 0.6431,  ..., 0.5804, 0.6235, 0.6784],\n",
       "          [0.6118, 0.6235, 0.6235,  ..., 0.5451, 0.5922, 0.6588]],\n",
       "\n",
       "         [[0.0510, 0.0510, 0.0588,  ..., 0.6235, 0.6667, 0.5961],\n",
       "          [0.0549, 0.0588, 0.0667,  ..., 0.5882, 0.6392, 0.6549],\n",
       "          [0.0627, 0.0588, 0.0392,  ..., 0.5647, 0.5961, 0.6431],\n",
       "          ...,\n",
       "          [0.6431, 0.6392, 0.6627,  ..., 0.6039, 0.6824, 0.7020],\n",
       "          [0.6431, 0.6353, 0.6431,  ..., 0.5804, 0.6235, 0.6784],\n",
       "          [0.6118, 0.6235, 0.6235,  ..., 0.5451, 0.5922, 0.6588]],\n",
       "\n",
       "         [[0.0510, 0.0510, 0.0588,  ..., 0.6235, 0.6667, 0.5961],\n",
       "          [0.0549, 0.0588, 0.0667,  ..., 0.5882, 0.6392, 0.6549],\n",
       "          [0.0627, 0.0588, 0.0392,  ..., 0.5647, 0.5961, 0.6431],\n",
       "          ...,\n",
       "          [0.6431, 0.6392, 0.6627,  ..., 0.6039, 0.6824, 0.7020],\n",
       "          [0.6431, 0.6353, 0.6431,  ..., 0.5804, 0.6235, 0.6784],\n",
       "          [0.6118, 0.6235, 0.6235,  ..., 0.5451, 0.5922, 0.6588]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.4824, 0.4863, 0.4863,  ..., 0.5098, 0.5020, 0.4941],\n",
       "          [0.4863, 0.4902, 0.4902,  ..., 0.5059, 0.5059, 0.5059],\n",
       "          [0.4902, 0.4941, 0.4941,  ..., 0.5020, 0.5059, 0.5098],\n",
       "          ...,\n",
       "          [0.0980, 0.0627, 0.0471,  ..., 0.5843, 0.6118, 0.6510],\n",
       "          [0.0863, 0.0588, 0.0471,  ..., 0.5804, 0.6000, 0.6431],\n",
       "          [0.0863, 0.0627, 0.0510,  ..., 0.5804, 0.6000, 0.6431]],\n",
       "\n",
       "         [[0.4824, 0.4863, 0.4863,  ..., 0.5098, 0.5020, 0.4941],\n",
       "          [0.4863, 0.4902, 0.4902,  ..., 0.5059, 0.5059, 0.5059],\n",
       "          [0.4902, 0.4941, 0.4941,  ..., 0.5020, 0.5059, 0.5098],\n",
       "          ...,\n",
       "          [0.0980, 0.0627, 0.0471,  ..., 0.5843, 0.6118, 0.6510],\n",
       "          [0.0863, 0.0588, 0.0471,  ..., 0.5804, 0.6000, 0.6431],\n",
       "          [0.0863, 0.0627, 0.0510,  ..., 0.5804, 0.6000, 0.6431]],\n",
       "\n",
       "         [[0.4824, 0.4863, 0.4863,  ..., 0.5098, 0.5020, 0.4941],\n",
       "          [0.4863, 0.4902, 0.4902,  ..., 0.5059, 0.5059, 0.5059],\n",
       "          [0.4902, 0.4941, 0.4941,  ..., 0.5020, 0.5059, 0.5098],\n",
       "          ...,\n",
       "          [0.0980, 0.0627, 0.0471,  ..., 0.5843, 0.6118, 0.6510],\n",
       "          [0.0863, 0.0588, 0.0471,  ..., 0.5804, 0.6000, 0.6431],\n",
       "          [0.0863, 0.0627, 0.0510,  ..., 0.5804, 0.6000, 0.6431]]],\n",
       "\n",
       "\n",
       "        [[[0.5412, 0.5294, 0.5333,  ..., 0.0588, 0.1020, 0.1216],\n",
       "          [0.5294, 0.4980, 0.5020,  ..., 0.0941, 0.1255, 0.0980],\n",
       "          [0.5059, 0.4784, 0.4627,  ..., 0.0745, 0.0745, 0.0392],\n",
       "          ...,\n",
       "          [0.6157, 0.6078, 0.5961,  ..., 0.1137, 0.1059, 0.1098],\n",
       "          [0.5569, 0.5490, 0.5490,  ..., 0.0902, 0.1216, 0.1333],\n",
       "          [0.5451, 0.5490, 0.5569,  ..., 0.1412, 0.1569, 0.1490]],\n",
       "\n",
       "         [[0.5412, 0.5294, 0.5333,  ..., 0.0588, 0.1020, 0.1216],\n",
       "          [0.5294, 0.4980, 0.5020,  ..., 0.0941, 0.1255, 0.0980],\n",
       "          [0.5059, 0.4784, 0.4627,  ..., 0.0745, 0.0745, 0.0392],\n",
       "          ...,\n",
       "          [0.6157, 0.6078, 0.5961,  ..., 0.1137, 0.1059, 0.1098],\n",
       "          [0.5569, 0.5490, 0.5490,  ..., 0.0902, 0.1216, 0.1333],\n",
       "          [0.5451, 0.5490, 0.5569,  ..., 0.1412, 0.1569, 0.1490]],\n",
       "\n",
       "         [[0.5412, 0.5294, 0.5333,  ..., 0.0588, 0.1020, 0.1216],\n",
       "          [0.5294, 0.4980, 0.5020,  ..., 0.0941, 0.1255, 0.0980],\n",
       "          [0.5059, 0.4784, 0.4627,  ..., 0.0745, 0.0745, 0.0392],\n",
       "          ...,\n",
       "          [0.6157, 0.6078, 0.5961,  ..., 0.1137, 0.1059, 0.1098],\n",
       "          [0.5569, 0.5490, 0.5490,  ..., 0.0902, 0.1216, 0.1333],\n",
       "          [0.5451, 0.5490, 0.5569,  ..., 0.1412, 0.1569, 0.1490]]],\n",
       "\n",
       "\n",
       "        [[[0.4863, 0.4784, 0.4902,  ..., 0.4941, 0.5059, 0.5020],\n",
       "          [0.4627, 0.4627, 0.4667,  ..., 0.4902, 0.4941, 0.4980],\n",
       "          [0.4706, 0.4745, 0.4745,  ..., 0.4824, 0.5059, 0.5255],\n",
       "          ...,\n",
       "          [0.0353, 0.0275, 0.0314,  ..., 0.5216, 0.5490, 0.5451],\n",
       "          [0.0392, 0.0353, 0.0314,  ..., 0.4980, 0.5373, 0.5412],\n",
       "          [0.0353, 0.0392, 0.0392,  ..., 0.4745, 0.5333, 0.5529]],\n",
       "\n",
       "         [[0.4863, 0.4784, 0.4902,  ..., 0.4941, 0.5059, 0.5020],\n",
       "          [0.4627, 0.4627, 0.4667,  ..., 0.4902, 0.4941, 0.4980],\n",
       "          [0.4706, 0.4745, 0.4745,  ..., 0.4824, 0.5059, 0.5255],\n",
       "          ...,\n",
       "          [0.0353, 0.0275, 0.0314,  ..., 0.5216, 0.5490, 0.5451],\n",
       "          [0.0392, 0.0353, 0.0314,  ..., 0.4980, 0.5373, 0.5412],\n",
       "          [0.0353, 0.0392, 0.0392,  ..., 0.4745, 0.5333, 0.5529]],\n",
       "\n",
       "         [[0.4863, 0.4784, 0.4902,  ..., 0.4941, 0.5059, 0.5020],\n",
       "          [0.4627, 0.4627, 0.4667,  ..., 0.4902, 0.4941, 0.4980],\n",
       "          [0.4706, 0.4745, 0.4745,  ..., 0.4824, 0.5059, 0.5255],\n",
       "          ...,\n",
       "          [0.0353, 0.0275, 0.0314,  ..., 0.5216, 0.5490, 0.5451],\n",
       "          [0.0392, 0.0353, 0.0314,  ..., 0.4980, 0.5373, 0.5412],\n",
       "          [0.0353, 0.0392, 0.0392,  ..., 0.4745, 0.5333, 0.5529]]]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(train_minibatches_iterator)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we look at the 'debugging' model (main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loss\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import models\n",
    "import train\n",
    "from datasets import NoduleDataset, SubtypedDataLoader\n",
    "from fast_data_loader import InfiniteDataLoader\n",
    "\n",
    "id_name = 'noduleID'\n",
    "feature_names = ['Area', 'ConvexArea', 'Perimeter', 'ConvexPerimeter', 'EquivDiameter',\n",
    "                 'MajorAxisLength', 'MinorAxisLength', 'SuperscribedDiameter',\n",
    "                 'Elongation', 'Compactness', 'Eccentricity', 'Solidity', 'Extent',\n",
    "                 'Circularity', 'RadialDistanceSD', 'SecondMoment', 'Roughness',\n",
    "                 'MaxIntensity', 'MeanIntensity', 'SDIntensity', 'MinIntensityBG',\n",
    "                 'MaxIntensityBG', 'MeanIntensityBG', 'SDIntensityBG',\n",
    "                 'IntensityDifference', 'markov1', 'markov2', 'markov3', 'markov4',\n",
    "                 'markov5', 'gabormean_0_0', 'gaborSD_0_0', 'gabormean_0_1',\n",
    "                 'gaborSD_0_1', 'gabormean_0_2', 'gaborSD_0_2', 'gabormean_1_0',\n",
    "                 'gaborSD_1_0', 'gabormean_1_1', 'gaborSD_1_1', 'gabormean_1_2',\n",
    "                 'gaborSD_1_2', 'gabormean_2_0', 'gaborSD_2_0', 'gabormean_2_1',\n",
    "                 'gaborSD_2_1', 'gabormean_2_2', 'gaborSD_2_2', 'gabormean_3_0',\n",
    "                 'gaborSD_3_0', 'gabormean_3_1', 'gaborSD_3_1', 'gabormean_3_2',\n",
    "                 'gaborSD_3_2', 'Contrast', 'Correlation', 'Energy', 'Homogeneity',\n",
    "                 'Entropy', 'x_3rdordermoment', 'Inversevariance', 'Sumaverage',\n",
    "                 'Variance', 'Clustertendency']\n",
    "label_name = 'malignancy'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "training_fraction = 0.8\n",
    "batch_size = 4\n",
    "epoch_size = 23\n",
    "\n",
    "is_gdro = False\n",
    "\n",
    "groupdro_hparams = {\"groupdro_eta\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # select features and labels\n",
    "    df = df.loc[:, [id_name, *feature_names, label_name]]\n",
    "\n",
    "    # remove malignancy = 3\n",
    "    df = df[df[label_name] != 3]\n",
    "\n",
    "    # binarize the remaining malignancy [1,2] -> 0, [4,5] -> 1\n",
    "    df[label_name] = [int(m - 3 > 0) for m in df[label_name]]\n",
    "\n",
    "    # normalize numeric features\n",
    "    df.loc[:, feature_names] = StandardScaler().fit_transform(df.loc[:, feature_names].values)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_to_tensors(df, frac):\n",
    "    # separate into training and test sets\n",
    "    training_df = df.sample(frac=frac)\n",
    "    test_df = df.drop(training_df.index)\n",
    "\n",
    "    # tensorify\n",
    "    training_data = torch.FloatTensor(training_df.loc[:, feature_names].values).to(device)\n",
    "    training_labels = torch.LongTensor(training_df.loc[:, label_name].values).to(device)\n",
    "    test_data = torch.FloatTensor(test_df.loc[:, feature_names].values).to(device)\n",
    "    test_labels = torch.LongTensor(test_df.loc[:, label_name].values).to(device)\n",
    "\n",
    "    return training_data, training_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "def create_dataloaders(df):\n",
    "    training_data, training_labels, test_data, test_labels = split_to_tensors(df, training_fraction)\n",
    "\n",
    "    # wrap with datasets and dataloaders\n",
    "    train_dataloader = iter(InfiniteDataLoader(NoduleDataset(training_data, training_labels), batch_size=batch_size))\n",
    "    test_dataloader = iter(InfiniteDataLoader(NoduleDataset(test_data, test_labels), batch_size=batch_size))\n",
    "\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "def create_subtyped_dataloaders(df, subtype_df):\n",
    "    def get_subtype_data(subtype_name):\n",
    "        return df.loc[\n",
    "               [subtype_df.at[nodule_id, \"subtype\"] == subtype_name\n",
    "                if nodule_id in subtype_df[\"Nodule_id\"].values else False\n",
    "                for nodule_id in df[id_name]], :]\n",
    "\n",
    "    subtype_names = subtype_df[\"subtype\"].unique()\n",
    "    subtype_dfs = {name: get_subtype_data(name) for name in subtype_names}\n",
    "\n",
    "    # separate into training and test sets\n",
    "    training_subtype_data = test_subtype_data = {}\n",
    "    for name in subtype_dfs:\n",
    "        training_data, training_labels, test_data, test_labels = split_to_tensors(subtype_dfs[name], training_fraction)\n",
    "\n",
    "        training_subtype_data[name] = (training_data, training_labels)\n",
    "        test_subtype_data[name] = (test_data, test_labels)\n",
    "\n",
    "    # wrap with datasets and dataloaders\n",
    "    train_dataloader = SubtypedDataLoader(training_subtype_data, batch_size=batch_size)\n",
    "    test_dataloader = SubtypedDataLoader(test_subtype_data, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # import data\n",
    "df = pd.read_csv(\"../data/LIDC_20130817_AllFeatures2D_MaxSlicePerNodule_inLineRatings.csv\")\n",
    "subtype_df = pd.read_csv(\"../data/lidc_subtyped.csv\")\n",
    "\n",
    "# preprocess data\n",
    "df = preprocess_data(df)\n",
    "subtype_df.index = subtype_df[\"Nodule_id\"].values\n",
    "\n",
    "# create the training and testing dataloaders\n",
    "if is_gdro:\n",
    "    train_dataloader, test_dataloader = create_subtyped_dataloaders(df, subtype_df)\n",
    "else:\n",
    "    train_dataloader, test_dataloader = create_dataloaders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dataloader)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(4).unsqueeze(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([[0,0,-1,-1,-1], [1,-1,-1,-1,-1],[2,2,2,2,2],[3,3,-1,-1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 5, 2])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b==a).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU",
   "language": "python",
   "name": "reu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
