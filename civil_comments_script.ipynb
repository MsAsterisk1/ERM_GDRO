{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MsAsterisk1/ERM_GDRO/blob/main/civil_comments_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UJn54eo6aTIC"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCeDv917mrC6",
    "outputId": "6206725f-8228-4122-83c8-545c99c18f7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2060 (UUID: GPU-100f20af-1b36-5adc-0795-f06b020c050b)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pwy_5DbGZgk",
    "outputId": "63ae86f4-a027-4edb-ded2-c241bd8d3f33"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/MsAsterisk1/ERM_GDRO.git\n",
    "# %cd /content/ERM_GDRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QE2ClDuV-7mx"
   },
   "outputs": [],
   "source": [
    "# !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZ8NiHj3dQim",
    "outputId": "848d4fd5-b2de-4a71-829e-f3d9c6796a42",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NsA17YlmbQ-8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.process_data_utils import  get_CivilComments_DataLoaders, get_CivilComments_Datasets, get_CivilComments_df\n",
    "from loss import ERMLoss, GDROLoss\n",
    "from train_eval import train, evaluate, train_epochs\n",
    "import torch\n",
    "from models import BertClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUx_MfAZdOtB"
   },
   "source": [
    "Now lets try getting Bert working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "tiSrSPzdBN9q",
    "outputId": "b4ff6b24-94dc-4e74-a206-7846e8584317"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cPlJw_w0Jclx"
   },
   "outputs": [],
   "source": [
    "df = get_CivilComments_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K3_JuPgTDPg-"
   },
   "outputs": [],
   "source": [
    "datasets = get_CivilComments_Datasets(CC_df=df, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7_G3XT5g_OPa"
   },
   "outputs": [],
   "source": [
    "tr,cv,test = get_CivilComments_DataLoaders(datasets=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7n857zmGfiK2"
   },
   "source": [
    "This is how we would initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxdghEABLCrn",
    "outputId": "5c6a7842-b1b2-4890-803f-8039fe83f582"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5\n",
      "Average training loss: 0.2264478290124004\n",
      "For Cross Val:\n",
      "Loss: 0.22557975351810455 Accuracy: 0.9049358123063302 \n",
      "Accuracy over subgroups: [0.60699301 0.5849546  0.55865922 0.47916667 0.54296875 0.2\n",
      " 0.67354597 0.62676056 0.68678029 0.92444444 0.93417969 0.83894449\n",
      " 0.9668747  0.88861076 0.92592593 0.77479893 0.79950372 0.95365328] \n",
      "Worst Group Accuracy: 0.2\n",
      "Epoch 2 / 5\n",
      "Average training loss: 0.21623695677513527\n",
      "For Cross Val:\n",
      "Loss: 0.23032869398593903 Accuracy: 0.8903718459495352 \n",
      "Accuracy over subgroups: [0.7020979  0.65888457 0.70949721 0.57291667 0.66992188 0.6\n",
      " 0.79924953 0.77699531 0.72409028 0.88987654 0.90390625 0.70973612\n",
      " 0.94959193 0.80913642 0.92592593 0.63538874 0.64813896 0.94201763] \n",
      "Worst Group Accuracy: 0.5729166666666666\n",
      "Epoch 3 / 5\n",
      "Average training loss: 0.2140838625643944\n",
      "For Cross Val:\n",
      "Loss: 0.20929887890815735 Accuracy: 0.9173085436033643 \n",
      "Accuracy over subgroups: [0.4027972  0.40726329 0.34636872 0.26041667 0.33398438 0.\n",
      " 0.37898687 0.39319249 0.50391525 0.96938272 0.97265625 0.9399454\n",
      " 0.99039846 0.9649562  1.         0.9285076  0.93151365 0.98385896] \n",
      "Worst Group Accuracy: 0.0\n",
      "Epoch 4 / 5\n",
      "Average training loss: 0.2086389120977229\n",
      "For Cross Val:\n",
      "Loss: 0.20445458590984344 Accuracy: 0.9171978751660027 \n",
      "Accuracy over subgroups: [0.43496503 0.44357977 0.40782123 0.28645833 0.36132812 0.\n",
      " 0.46716698 0.44131455 0.52372179 0.9617284  0.96660156 0.92083712\n",
      " 0.98799808 0.95306633 0.96296296 0.8945487  0.90918114 0.98205681] \n",
      "Worst Group Accuracy: 0.0\n",
      "Epoch 5 / 5\n",
      "Average training loss: 0.2050100893639593\n",
      "For Cross Val:\n",
      "Loss: 0.20334970951080322 Accuracy: 0.9171314741035856 \n",
      "Accuracy over subgroups: [0.51188811 0.50194553 0.46648045 0.32552083 0.41601562 0.\n",
      " 0.55534709 0.51408451 0.57438968 0.95481481 0.95546875 0.89080983\n",
      " 0.9824772  0.94242804 0.96296296 0.86595174 0.88387097 0.97712047] \n",
      "Worst Group Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier(device=DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.01)\n",
    "epochs = 5\n",
    "loss_fn = ERMLoss(model, torch.nn.CrossEntropyLoss())\n",
    "# loss_fn = GDROLoss(model, torch.nn.CrossEntropyLoss(), 0.01, 8, vector_subclass=True)\n",
    "\n",
    "train_epochs(epochs, tr, cv, model, loss_fn, optimizer, vector_subclass=True, verbose=True, num_subclasses=18, save_weights_name='CC_ERM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of utils.process_data_utils failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tzeng1\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\extensions\\autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\tzeng1\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\tzeng1\\repos\\ERM_GDRO\\utils\\process_data_utils.py\", line 5, in <module>\n",
      "    from wilds import get_dataset\n",
      "ModuleNotFoundError: No module named 'wilds'\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9160200923891106 \n",
      "Accuracy over subgroups: [0.52065365 0.50881057 0.53700658 0.4047619  0.43577136 0.21428571\n",
      " 0.56668835 0.53294746 0.57015825 0.94748594 0.95711968 0.87133956\n",
      " 0.97686142 0.92810458 0.98019802 0.85007496 0.88956841 0.97650703] \n",
      "Worst Group Accuracy: 0.21428571428571427\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate(test, model, 18, vector_subclass=True, replacement=False, get_loss=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./epoch_2_CC_ERM.wt'))\n",
    "_ = evaluate(test, model, 18, vector_subclass=True, replacement=False, get_loss=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.917021721905787 \n",
      "Accuracy over subgroups: [0.43758511 0.42687225 0.40296053 0.32777778 0.34357714 0.14285714\n",
      " 0.41314249 0.42742654 0.50293896 0.96543169 0.97355244 0.9211838\n",
      " 0.98545575 0.95966387 0.99009901 0.92413793 0.93377599 0.98365992] \n",
      "Worst Group Accuracy: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./epoch_3_CC_ERM.wt'))\n",
    "_ = evaluate(test, model, 18, vector_subclass=True, replacement=False, get_loss=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_epochs() missing 1 required positional argument: 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# loss_fn = ERMLoss(model, torch.nn.CrossEntropyLoss())\u001b[39;00m\n\u001b[0;32m      5\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m GDROLoss(model, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m18\u001b[39m, vector_subclass\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_subclass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_subclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCC_GDRO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: train_epochs() missing 1 required positional argument: 'optimizer'"
     ]
    }
   ],
   "source": [
    "model = BertClassifier(device=DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.01)\n",
    "epochs = 5\n",
    "# loss_fn = ERMLoss(model, torch.nn.CrossEntropyLoss())\n",
    "loss_fn = GDROLoss(model, torch.nn.CrossEntropyLoss(), 0.01, 18, vector_subclass=True)\n",
    "\n",
    "train_epochs(epochs, tr, cv, model, loss_fn, optimizer, vector_subclass=True, verbose=True, num_subclasses=18, save_weights_name='CC_GDRO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate(test, model, 18, vector_subclass=True, replacement=False, get_loss=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run again to make sure \n",
    "_ = evaluate(test, model, 18, vector_subclass=True, replacement=False, get_loss=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./epoch_3_CC_ERM.wt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./epoch_2_CC_GDRO.wt'))\n",
    "_ = evaluate(test, model, 18, vector_subclass=True, replacement=False, get_loss=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPUiuP8oFwoTkVWCrrQzyn9",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "civil_comments_test.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "REU",
   "language": "python",
   "name": "reu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
